{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"},{"sourceId":1803569,"sourceType":"datasetVersion","datasetId":1071580},{"sourceId":653332,"sourceType":"modelInstanceVersion","modelInstanceId":493548,"modelId":508969},{"sourceId":3730,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":2657,"modelId":312}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import os\nSET_SEED=42\nos.environ['PYTHONHASHSEED'] = str(SET_SEED)\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.098754Z","iopub.execute_input":"2025-11-26T18:36:39.099075Z","iopub.status.idle":"2025-11-26T18:36:39.103297Z","shell.execute_reply.started":"2025-11-26T18:36:39.099051Z","shell.execute_reply":"2025-11-26T18:36:39.102685Z"}},"outputs":[],"execution_count":300},{"cell_type":"code","source":"import torch\nimport copy\nimport sklearn\nimport gc\nimport timm\nimport time\nimport safetensors\nimport random\nimport warnings\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom safetensors.torch import load_file\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.preprocessing import StandardScaler\nfrom torchvision import transforms, models\nfrom collections import defaultdict\nfrom sklearn.model_selection import GroupKFold\nfrom scipy.stats import zscore, norm, laplace\n\nwarnings.filterwarnings(\"ignore\", message=\".*does not have a deterministic implementation.*\")\n\n# if os.environ.get('KAGGLE_KERNEL_RUN_TYPE') != 'Batch':\n#     !pip install -q ipdb\n#     import ipdb","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.105184Z","iopub.execute_input":"2025-11-26T18:36:39.105391Z","iopub.status.idle":"2025-11-26T18:36:39.126025Z","shell.execute_reply.started":"2025-11-26T18:36:39.105358Z","shell.execute_reply":"2025-11-26T18:36:39.125562Z"}},"outputs":[],"execution_count":301},{"cell_type":"code","source":"def set_seed(seed=SET_SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    try:\n        torch.use_deterministic_algorithms(True, warn_only=True)\n    except AttributeError:\n        pass  # Older PyTorch versions\n    \n\nset_seed(SET_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.127361Z","iopub.execute_input":"2025-11-26T18:36:39.127696Z","iopub.status.idle":"2025-11-26T18:36:39.144644Z","shell.execute_reply.started":"2025-11-26T18:36:39.127672Z","shell.execute_reply":"2025-11-26T18:36:39.144095Z"}},"outputs":[],"execution_count":302},{"cell_type":"code","source":"# Hyperparameters\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBATCH_SIZE = 16\nNUM_FT_EPOCHS = 20\nNUM_BB_EPOCHS = 12\nLEARNING_RATE = 0.0001\nWEIGHT_DECAY = 1e-4\nNUM_FOLDS = 1\nGIVEN_WEIGHTS = [0.1, 0.1, 0.1, 0.5, 0.2]\nTARGET_COLS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\nBINARY_COLS = TARGET_COLS[:3]\nBASE_MODEL='efficientnet_b1'\nIMAGE_SIZE=(392,392)\nTRAIN_SHUFFLE=0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.145202Z","iopub.execute_input":"2025-11-26T18:36:39.145372Z","iopub.status.idle":"2025-11-26T18:36:39.159562Z","shell.execute_reply.started":"2025-11-26T18:36:39.145357Z","shell.execute_reply":"2025-11-26T18:36:39.158919Z"}},"outputs":[],"execution_count":303},{"cell_type":"code","source":"def print_result(train_loss, val_loss, epoch_start, epoch, num_epochs, val_r2):\n    epoch_time = time.time() - epoch_start\n    mins, secs = divmod(epoch_time, 60)\n    \n    print(f'Epoch {epoch+1}/{num_epochs} - '\n          f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} | '\n          f'R²: {val_r2:.4f} | '\n          f'Time: {int(mins)}m {int(secs)}s')\n\nclass BiomassDataset(torch.utils.data.Dataset):\n    def __init__(self, df, base_path, transform=None):\n        self.df = df\n        self.base_path = base_path\n        self.transform = transform\n        self.target_cols = TARGET_COLS\n        self.is_training = all(col in df.columns for col in self.target_cols)\n        if self.is_training:\n            self.is_nonzero = (df[BINARY_COLS].values > 0).astype(np.float32)\n            self.targets = df[self.target_cols].values.astype(np.float32)\n            self.targets_log = np.log1p(np.where(self.targets > 0, self.targets, 0))\n            self.targets_mean = np.nanmean(self.targets_log, axis=0)\n            self.targets_std = np.nanstd(self.targets_log, axis=0) + 1e-8\n            self.targets_norm = (self.targets_log - self.targets_mean) / self.targets_std\n            self.targets_norm_masked = self.targets_norm.copy()\n            self.targets_norm_masked[:, :3] = np.where(\n                self.is_nonzero, self.targets_norm[:, :3], 0.0\n            ) # first 3 cols\n            print(self.targets_norm_masked) \n\n    def denormalize(self, normalized_targets):\n        device = normalized_targets.device\n        means = torch.tensor(self.targets_mean, dtype=torch.float32, device=device)\n        stds = torch.tensor(self.targets_std, dtype=torch.float32, device=device)\n        if normalized_targets.dim() == 1:\n            return normalized_targets * stds + means\n        else:\n            return normalized_targets * stds.unsqueeze(0) + means.unsqueeze(0)\n    \n    def __len__(self):\n        return len(self.df)\n\n    def _get_crop(self, image, crop_type):\n        \"\"\"Get different crop from image\"\"\"\n        width, height = image.size\n        \n        if crop_type == 0:  # Left half\n            return image.crop((0, 0, width // 2, height))\n        elif crop_type == 1:  # Right half\n            return image.crop((width // 2, 0, width, height))\n        elif crop_type == 2:  # Top half\n            return image.crop((0, 0, width, height // 2))\n        elif crop_type == 3:  # Bottom half\n            return image.crop((0, height // 2, width, height))\n        else:  # Center crop (80% of image)\n            crop_w, crop_h = int(width * 0.8), int(height * 0.8)\n            left = (width - crop_w) // 2\n            top = (height - crop_h) // 2\n            return image.crop((left, top, left + crop_w, top + crop_h))\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx // 5] \n        img_path = os.path.join(self.base_path, row['image_path'])\n        \n        image = Image.open(img_path).convert('RGB')\n        # crop_type = idx % 5\n        # image = self._get_crop(image, crop_type)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_training:\n            is_nonzero = torch.tensor(self.is_nonzero[idx, :3], dtype=torch.float32)\n            targets = torch.tensor(self.targets_norm_masked[idx], dtype=torch.float32)\n            return image, (is_nonzero, targets)\n            # targets = row[self.target_cols].values.astype('float32')\n            # targets_normalized = (targets - TARGET_MEANS.numpy()) / TARGET_STDS.numpy()\n            \n            # return image, torch.tensor(targets_normalized, dtype=torch.float32)\n        else:            \n            return image, row['image_path']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T19:11:07.445050Z","iopub.execute_input":"2025-11-26T19:11:07.445365Z","iopub.status.idle":"2025-11-26T19:11:07.458641Z","shell.execute_reply.started":"2025-11-26T19:11:07.445343Z","shell.execute_reply":"2025-11-26T19:11:07.457697Z"}},"outputs":[],"execution_count":322},{"cell_type":"code","source":"class FinetuneModel(nn.Module):\n    def __init__(self, pretrained_backbone=None):\n        super().__init__()\n        self.backbone = timm.create_model('tf_efficientnet_b1', pretrained=False, num_classes=0)\n        model_path = '/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b1/1/tf_efficientnet_b1_aa-ea7a6ee0.pth'\n        checkpoint = torch.load(model_path)\n        self.backbone.load_state_dict(checkpoint, strict=False)\n        \n        feature_dim = self.backbone.num_features\n\n        self.binary_head = nn.Sequential(\n            nn.Linear(feature_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 3),\n            nn.Sigmoid()  # output probability for each target\n        )\n\n        self.regression_head = nn.Sequential(\n            nn.Linear(feature_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(64, 5), # 5 outputs for competition\n            # nn.ReLU()\n        )\n\n        self._init_head_weights()\n    \n    def _init_head_weights(self):\n        \"\"\"Initialize regression head with deterministic weights\"\"\"\n        for m in self.regression_head.modules():\n            if isinstance(m, nn.Linear):\n                # Use a fixed seed for weight initialization\n                with torch.random.fork_rng():\n                    torch.manual_seed(SET_SEED)\n                    torch.nn.init.xavier_uniform_(m.weight)\n                    if m.bias is not None:\n                        torch.nn.init.zeros_(m.bias)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        binary_out = self.binary_head(features) \n        regression_out = self.regression_head(features) \n        return binary_out, regression_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.221816Z","iopub.execute_input":"2025-11-26T18:36:39.222004Z","iopub.status.idle":"2025-11-26T18:36:39.239943Z","shell.execute_reply.started":"2025-11-26T18:36:39.221989Z","shell.execute_reply":"2025-11-26T18:36:39.239441Z"}},"outputs":[],"execution_count":305},{"cell_type":"code","source":"base = '/kaggle/input'\ntrain_csv = f'{base}/csiro-biomass/train.csv'\ntest_csv = f'{base}/csiro-biomass/test.csv'\nextra_csv = f'{base}/grassclover-dataset/biomass_data/train/biomass_train_data.csv'\nextra_img = f'{base}/grassclover-dataset/biomass_data/train/images'\nbase_path = f'{base}/csiro-biomass/'\nsubmission_path = f'{base}/csiro-biomass/sample_submission.csv'\n\ndataset_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\nextra_df = pd.read_csv(extra_csv, sep=';')\nextra_img_path = extra_img\nunique_test_images = test_df['image_path'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.240714Z","iopub.execute_input":"2025-11-26T18:36:39.241122Z","iopub.status.idle":"2025-11-26T18:36:39.275211Z","shell.execute_reply.started":"2025-11-26T18:36:39.241106Z","shell.execute_reply":"2025-11-26T18:36:39.274561Z"}},"outputs":[],"execution_count":306},{"cell_type":"code","source":"dataset_df['Sampling_Date'] = pd.to_datetime(dataset_df['Sampling_Date'], format='mixed')  # adjust format if needed\ndataset_df = dataset_df.pivot(\n    index=['image_path','Sampling_Date'],\n    columns='target_name',\n    values='target'\n).reset_index()\ndataset_df['Month'] = dataset_df['Sampling_Date'].dt.month\ndataset_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.275988Z","iopub.execute_input":"2025-11-26T18:36:39.276227Z","iopub.status.idle":"2025-11-26T18:36:39.288196Z","shell.execute_reply.started":"2025-11-26T18:36:39.276212Z","shell.execute_reply":"2025-11-26T18:36:39.287502Z"}},"outputs":[{"execution_count":307,"output_type":"execute_result","data":{"text/plain":"Index(['image_path', 'Sampling_Date', 'Dry_Clover_g', 'Dry_Dead_g',\n       'Dry_Green_g', 'Dry_Total_g', 'GDM_g', 'Month'],\n      dtype='object', name='target_name')"},"metadata":{}}],"execution_count":307},{"cell_type":"markdown","source":"### Pytorch","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),  # Grass can be flipped\n    transforms.RandomRotation(degrees=15),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n    transforms.ColorJitter(\n        brightness=0.1,  # Sunlight variations\n        contrast=0.1,     # Different lighting\n        saturation=0.1,  # Grass color variations\n        hue=0.1\n    ),\n    transforms.RandomApply([ \n        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)) # Advanced augmentations\n    ], p=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                       std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                       std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.320399Z","iopub.execute_input":"2025-11-26T18:36:39.320621Z","iopub.status.idle":"2025-11-26T18:36:39.338697Z","shell.execute_reply.started":"2025-11-26T18:36:39.320602Z","shell.execute_reply":"2025-11-26T18:36:39.338154Z"}},"outputs":[],"execution_count":310},{"cell_type":"markdown","source":"### Support Functions","metadata":{}},{"cell_type":"code","source":"def forward_pass(images, is_nonzero, targets, model, optimizer=None):\n    images = images.to(device)\n    is_nonzero = is_nonzero.to(device)\n    targets = targets.to(device)\n\n    pred_binary, pred_regression = model(images)\n\n    # Only first 3 columns for BCE\n    loss = combined_hurdle_loss(pred_binary, pred_regression, is_nonzero, targets)\n\n    if optimizer is not None:  # training\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    return loss, pred_binary, pred_regression","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.339523Z","iopub.execute_input":"2025-11-26T18:36:39.339819Z","iopub.status.idle":"2025-11-26T18:36:39.354019Z","shell.execute_reply.started":"2025-11-26T18:36:39.339799Z","shell.execute_reply":"2025-11-26T18:36:39.353431Z"}},"outputs":[],"execution_count":311},{"cell_type":"markdown","source":"### Train Model","metadata":{"execution":{"iopub.status.busy":"2025-11-14T12:22:03.521564Z","iopub.status.idle":"2025-11-14T12:22:03.522083Z","shell.execute_reply":"2025-11-14T12:22:03.521846Z","shell.execute_reply.started":"2025-11-14T12:22:03.521827Z"}}},{"cell_type":"code","source":"def combined_hurdle_loss(pred_binary, pred_regression, is_nonzero, targets, given_weights=GIVEN_WEIGHTS):\n    device = pred_regression.device\n    weights_full = torch.tensor(given_weights, device=device)\n\n    # -------------------------\n    # 1️⃣ Binary BCE (first 3 targets)\n    # -------------------------\n    bce_loss_fn = nn.BCELoss()\n    loss_binary = bce_loss_fn(pred_binary, is_nonzero)\n\n    # -------------------------\n    # 2️⃣ Regression loss (all 5 targets)\n    # -------------------------\n    # Create full mask: first 3 columns use is_nonzero, last 2 columns = 1\n    mask_full = torch.ones_like(pred_regression, device=device)\n    mask_full[:, :3] = is_nonzero  # only mask zeros for first 3 columns\n\n    # Smooth L1 + MSE\n    smooth_l1 = nn.SmoothL1Loss(reduction='none')\n    mse = nn.MSELoss(reduction='none')\n\n    smooth_l1_loss = smooth_l1(pred_regression, targets)\n    mse_loss = mse(pred_regression, targets)\n\n    combined_loss = 0.3 * smooth_l1_loss + 0.7 * mse_loss\n\n    # Apply mask and weights\n    weighted_loss = (combined_loss * weights_full * mask_full).sum() / mask_full.sum()\n\n    return loss_binary + weighted_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.354712Z","iopub.execute_input":"2025-11-26T18:36:39.354947Z","iopub.status.idle":"2025-11-26T18:36:39.371719Z","shell.execute_reply.started":"2025-11-26T18:36:39.354927Z","shell.execute_reply":"2025-11-26T18:36:39.370864Z"}},"outputs":[],"execution_count":312},{"cell_type":"code","source":"\ndef weighted_r2_score(sum_target, valid_samples, sum_target_sq, ss_res):\n    \"\"\"\n    Corrected weighted R² score calculation.\n    \n    Args:\n        sum_target: Sum of targets per column [5]\n        valid_samples: Number of valid samples per column [5] (accounts for masking)\n        sum_target_sq: Sum of squared targets per column [5]\n        ss_res: Sum of squared residuals per column [5]\n    \n    Returns:\n        Weighted R² score\n    \"\"\"\n    # Compute R² per column\n    r2_per_output = torch.zeros(5, device=device)\n    for col in range(5):\n        if valid_samples[col] > 0:\n            mean_target = sum_target[col] / valid_samples[col]\n            ss_tot = sum_target_sq[col] - valid_samples[col] * (mean_target ** 2)\n            r2_per_output[col] = 1 - ss_res[col] / (ss_tot + 1e-10)\n    \n    # Weight the R² scores\n    weights = torch.tensor(GIVEN_WEIGHTS, device=device)\n    r2_weighted = (r2_per_output * weights).sum() / weights.sum()\n    return r2_weighted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:36:39.372448Z","iopub.execute_input":"2025-11-26T18:36:39.372741Z","iopub.status.idle":"2025-11-26T18:36:39.391710Z","shell.execute_reply.started":"2025-11-26T18:36:39.372723Z","shell.execute_reply":"2025-11-26T18:36:39.391051Z"}},"outputs":[],"execution_count":313},{"cell_type":"code","source":"def create_data_loaders(train_df, val_df, batch_size=BATCH_SIZE):\n    train_dataset = BiomassDataset(train_df, base_path, transform=train_transform)\n    val_dataset = BiomassDataset(val_df, base_path, transform=val_transform)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=TRAIN_SHUFFLE, num_workers=0)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n    return train_loader, val_loader, train_dataset, val_dataset\n    \ndef train_epoch(model, train_loader, optimizer):\n    model.train()\n    total_loss = 0\n\n    for images, (is_nonzero, targets) in train_loader:\n        loss, _, _ = forward_pass(images, is_nonzero, targets, model, optimizer)\n        total_loss += loss.item()\n\n    return total_loss / len(train_loader)\n\ndef validate_epoch(model, val_loader, val_dataset):\n    \"\"\"\n    Corrected validation function with proper R² calculation.\n    \n    Key fixes:\n    - After denormalization, corrects masked zeros (sets to 0 instead of mean)\n    - Converts from log1p back to original scale using expm1\n    - Properly masks zeros for first 3 columns in R² calculation\n    - Computes R² per column with correct sample counts\n    \"\"\"\n    model.eval()\n    total_loss = 0\n\n    ss_res = torch.zeros(5, device=device)\n    sum_target = torch.zeros(5, device=device)\n    sum_target_sq = torch.zeros(5, device=device)\n    # Track valid samples per column (for first 3 columns, only count non-zero targets)\n    valid_samples = torch.zeros(5, device=device)\n\n    with torch.no_grad():\n        for images, (is_nonzero, targets) in val_loader:\n            images = images.to(device)\n            is_nonzero = is_nonzero.to(device)\n            targets = targets.to(device)\n            loss, pred_binary, pred_regression = forward_pass(\n                images, is_nonzero, targets, model, optimizer=None\n            )\n            total_loss += loss.item()\n    \n            # Denormalize: this gives us log1p values\n            pred_log = val_dataset.denormalize(pred_regression)\n            targets_log = val_dataset.denormalize(targets)\n            \n            # FIX: For first 3 columns, if is_nonzero=0, the normalized value was 0.0\n            # Denormalizing 0.0 gives mean_log1p, but we want log1p(0) = 0\n            # So set masked zeros to 0\n            targets_log[:, :3] = targets_log[:, :3] * is_nonzero\n            \n            # Convert from log1p back to original scale using expm1\n            pred_original = torch.expm1(pred_log)\n            targets_original = torch.expm1(targets_log)\n            \n            # For first 3 columns, only compute R² on non-zero targets\n            # For last 2 columns, use all samples\n            mask = torch.ones_like(targets_original, device=device)\n            mask[:, :3] = is_nonzero  # Mask zeros for first 3 columns\n            \n            # Compute squared residuals, sums, and valid sample counts\n            residuals_sq = ((pred_original - targets_original) ** 2) * mask\n            ss_res += residuals_sq.sum(dim=0)\n            sum_target += (targets_original * mask).sum(dim=0)\n            sum_target_sq += ((targets_original ** 2) * mask).sum(dim=0)\n            valid_samples += mask.sum(dim=0)\n\n    # Compute R² per column, then weight\n    r2_per_output = torch.zeros(5, device=device)\n    for col in range(5):\n        if valid_samples[col] > 0:\n            mean_target = sum_target[col] / valid_samples[col]\n            ss_tot = sum_target_sq[col] - valid_samples[col] * (mean_target ** 2)\n            r2_per_output[col] = 1 - ss_res[col] / (ss_tot + 1e-10)\n    \n    # Weight the R² scores\n    weights = torch.tensor(GIVEN_WEIGHTS, device=device)\n    r2_weighted = (r2_per_output * weights).sum() / weights.sum()\n    \n    return total_loss / len(val_loader), r2_weighted\n\ndef compute_fold_metrics(epoch_train_losses, epoch_val_losses, epoch_val_r2s):\n    best_val_idx = np.argmin(epoch_val_losses)\n    best_val_loss = epoch_val_losses[best_val_idx]\n    best_val_r2 = epoch_val_r2s[best_val_idx]\n    overfit_metric = epoch_train_losses[best_val_idx] - best_val_loss\n    stability_val_loss = np.mean(epoch_val_losses[-5:])\n    stability_val_r2 = np.mean(epoch_val_r2s[-5:])\n\n    metrics = {\n        \"best_val_loss\": best_val_loss,\n        \"best_val_r2\": best_val_r2,\n        \"overfit_metric\": overfit_metric,\n        \"stability_val_loss\": stability_val_loss,\n        \"stability_val_r2\": stability_val_r2\n    }\n    return metrics\n\ndef print_fold_metrics(fold, metrics):\n    print(f\"\\n--- Fold {fold + 1} Metrics Summary ---\")\n    print(f\"Best Val Loss: {metrics['best_val_loss']:.4f}\")\n    print(f\"Best Val R²: {metrics['best_val_r2']:.4f}\")\n    print(f\"Overfit Metric (train - val at best epoch): {metrics['overfit_metric']:.4f}\")\n    print(f\"Average Val Loss (last 5 epochs): {metrics['stability_val_loss']:.4f}\")\n    print(f\"Average Val R² (last 5 epochs): {metrics['stability_val_r2']:.4f}\")\n\n\ndef finetune_phase(pretrained_backbone=None, num_epochs=NUM_FT_EPOCHS):\n    print(\"\\n\" + \"=\" * 50)\n    print(\"PHASE 2: FINE-TUNING ON COMPETITION DATA\")\n    \n    r2 = []\n    fold_models = []\n\n    for fold, (train_idx, val_idx) in enumerate(splits):\n        print(f\"\\n--- Fold {fold + 1} Metrics Summary ---\")\n        train_df = dataset_df.iloc[train_idx].copy()\n        val_df = dataset_df.iloc[val_idx].copy()\n        train_loader, val_loader, train_dataset, val_dataset = create_data_loaders(train_df, val_df)\n\n        model = FinetuneModel().to(device)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n        \n        epoch_train_losses = []\n        epoch_val_losses = []\n        epoch_val_r2s = []\n    \n\n        for epoch in range(num_epochs):\n            epoch_start = time.time()\n            train_loss = train_epoch(model, train_loader, optimizer)\n            val_loss, val_r2 = validate_epoch(model, val_loader, val_dataset)\n\n            epoch_train_losses.append(train_loss)\n            epoch_val_losses.append(val_loss)\n            epoch_val_r2s.append(val_r2.item())\n            \n            print_result(train_loss, val_loss, epoch_start, epoch, num_epochs, val_r2)\n\n        r2.append(val_r2.item())\n        fold_models.append(model)\n        fold_metrics = compute_fold_metrics(epoch_train_losses, epoch_val_losses, epoch_val_r2s)\n        print_fold_metrics(fold, fold_metrics)\n\n    overall_r2 = np.array(r2).mean()\n    \n    print(f'\\nOverall R² across all folds: {overall_r2:.4f}')\n\n    return fold_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:44:42.751849Z","iopub.execute_input":"2025-11-26T18:44:42.752492Z","iopub.status.idle":"2025-11-26T18:44:42.768983Z","shell.execute_reply.started":"2025-11-26T18:44:42.752469Z","shell.execute_reply":"2025-11-26T18:44:42.768178Z"}},"outputs":[],"execution_count":318},{"cell_type":"code","source":"# Create a small dataset instance\nds = BiomassDataset(dataset_df.head(12), base_path, transform=None)\n\n# Loop over a few samples\nfor i in range(len(ds)):\n    image, (is_nonzero, targets) = ds[i]\n    print(f\"Sample {i}:\")\n    print(\"is_nonzero:\", is_nonzero)\n    print(\"targets (masked & normalized):\", targets)\n    print(\"-\" * 30)","metadata":{"execution":{"iopub.status.busy":"2025-11-26T18:36:39.411682Z","iopub.execute_input":"2025-11-26T18:36:39.411971Z","iopub.status.idle":"2025-11-26T18:36:39.941292Z","shell.execute_reply.started":"2025-11-26T18:36:39.411940Z","shell.execute_reply":"2025-11-26T18:36:39.940570Z"},"trusted":true,"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Sample 0:\nis_nonzero: tensor([0., 1., 1.])\ntargets (masked & normalized): tensor([ 0.0000,  1.3179,  0.5166,  0.7693, -0.2247])\n------------------------------\nSample 1:\nis_nonzero: tensor([0., 0., 1.])\ntargets (masked & normalized): tensor([ 0.0000,  0.0000, -0.0662, -1.7963, -1.3329])\n------------------------------\nSample 2:\nis_nonzero: tensor([1., 0., 0.])\ntargets (masked & normalized): tensor([ 0.4677,  0.0000,  0.0000, -2.0884, -1.6486])\n------------------------------\nSample 3:\nis_nonzero: tensor([0., 1., 1.])\ntargets (masked & normalized): tensor([0.0000, 1.2927, 0.8333, 0.9628, 0.3776])\n------------------------------\nSample 4:\nis_nonzero: tensor([1., 1., 1.])\ntargets (masked & normalized): tensor([-0.6543,  1.0714,  0.1785,  0.2743, -0.8088])\n------------------------------\nSample 5:\nis_nonzero: tensor([1., 1., 1.])\ntargets (masked & normalized): tensor([ 1.3331, -0.4460,  1.0623,  1.0311,  1.6514])\n------------------------------\nSample 6:\nis_nonzero: tensor([1., 1., 1.])\ntargets (masked & normalized): tensor([-0.2605, -0.3617,  0.3746, -0.6236, -0.3382])\n------------------------------\nSample 7:\nis_nonzero: tensor([1., 0., 0.])\ntargets (masked & normalized): tensor([1.9319, 0.0000, 0.0000, 0.9657, 1.6529])\n------------------------------\nSample 8:\nis_nonzero: tensor([0., 1., 1.])\ntargets (masked & normalized): tensor([0.0000, 0.5263, 0.6865, 0.1531, 0.0984])\n------------------------------\nSample 9:\nis_nonzero: tensor([1., 1., 1.])\ntargets (masked & normalized): tensor([0.3851, 0.3302, 0.9398, 0.5519, 0.8481])\n------------------------------\nSample 10:\nis_nonzero: tensor([1., 1., 1.])\ntargets (masked & normalized): tensor([ 1.2721,  0.2764, -1.1437,  0.1065,  0.2608])\n------------------------------\nSample 11:\nis_nonzero: tensor([1., 1., 1.])\ntargets (masked & normalized): tensor([-0.8413,  0.4047,  0.3469, -0.3064, -0.5361])\n------------------------------\n","output_type":"stream"}],"execution_count":315},{"cell_type":"code","source":"### NUM_FOLDS\n# NUM_FT_EPOCHS\n# kfold = GroupKFold(n_splits=NUM_FOLDS)\n# groups = dataset_df['Month']\n# splits = kfold.split(dataset_df, groups=groups)\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Make a single random split\ntrain_idx, val_idx = train_test_split(\n    np.arange(len(dataset_df)),\n    test_size=0.2,\n    shuffle=False,\n    random_state=42\n)\n\n# Wrap it in a list so enumerate() still works\nsplits = [(train_idx, val_idx)]\n\nfinal_model = finetune_phase(pretrained_backbone=False,num_epochs=2)\n# --- efficientb \n# Epoch 1/40 - Train Loss: 0.1669, Val Loss: 0.1252 | R²: 0.2158 | Time: 0m 50s\n# Epoch 2/40 - Train Loss: 0.1363, Val Loss: 0.1012 | R²: 0.3694 | Time: 0m 50s\n# Epoch 3/40 - Train Loss: 0.1186, Val Loss: 0.0877 | R²: 0.4542 | Time: 0m 50s\n# Epoch 4/40 - Train Loss: 0.1043, Val Loss: 0.0841 | R²: 0.4783 | Time: 0m 50s\n# Epoch 5/40 - Train Loss: 0.0916, Val Loss: 0.0814 | R²: 0.4980 | Time: 0m 50s\n# Epoch 6/40 - Train Loss: 0.0825, Val Loss: 0.0801 | R²: 0.5055 | Time: 0m 49s\n# Epoch 7/40 - Train Loss: 0.0831, Val Loss: 0.0750 | R²: 0.5377 | Time: 0m 50s\n# Epoch 8/40 - Train Loss: 0.0733, Val Loss: 0.0757 | R²: 0.5345 | Time: 0m 50s\n# Epoch 9/40 - Train Loss: 0.0717, Val Loss: 0.0778 | R²: 0.5194 | Time: 0m 50s\n# Epoch 10/40 - Train Loss: 0.0693, Val Loss: 0.0745 | R²: 0.5398 | Time: 0m 50s\n# Epoch 11/40 - Train Loss: 0.0671, Val Loss: 0.0713 | R²: 0.5599 | Time: 0m 50s\n# Epoch 12/40 - Train Loss: 0.0630, Val Loss: 0.0724 | R²: 0.5511 | Time: 0m 50s\n# Epoch 13/40 - Train Loss: 0.0587, Val Loss: 0.0759 | R²: 0.5284 | Time: 0m 50s\n# Epoch 14/40 - Train Loss: 0.0631, Val Loss: 0.0732 | R²: 0.5463 | Time: 0m 50s\n# Epoch 15/40 - Train Loss: 0.0568, Val Loss: 0.0688 | R²: 0.5731 | Time: 0m 50s\n# Epoch 16/40 - Train Loss: 0.0526, Val Loss: 0.0679 | R²: 0.5778 | Time: 0m 50s\n# Epoch 17/40 - Train Loss: 0.0543, Val Loss: 0.0669 | R²: 0.5858 | Time: 0m 50s\n# --- With  with higher weight decay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:44:46.963408Z","iopub.execute_input":"2025-11-26T18:44:46.963704Z","iopub.status.idle":"2025-11-26T18:45:50.278880Z","shell.execute_reply.started":"2025-11-26T18:44:46.963682Z","shell.execute_reply":"2025-11-26T18:45:50.278128Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nPHASE 2: FINE-TUNING ON COMPETITION DATA\n\n--- Fold 1 Metrics Summary ---\nEpoch 1/2 - Train Loss: 0.8684, Val Loss: 0.8227 | R²: -0.1976 | Time: 0m 31s\nEpoch 2/2 - Train Loss: 0.7949, Val Loss: 0.7429 | R²: -0.1904 | Time: 0m 31s\n\n--- Fold 1 Metrics Summary ---\nBest Val Loss: 0.7429\nBest Val R²: -0.1904\nOverfit Metric (train - val at best epoch): 0.0521\nAverage Val Loss (last 5 epochs): 0.7828\nAverage Val R² (last 5 epochs): -0.1940\n\nOverall R² across all folds: -0.1904\n","output_type":"stream"}],"execution_count":319},{"cell_type":"code","source":"test_dataset = BiomassDataset(test_df, base_path, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\nfold_models = final_model\nensemble_outputs = []\nwith torch.no_grad():\n    for image, img_path in test_loader:\n        image = image.to(device)\n        \n        # Get predictions from all models\n        all_outputs = []\n        for model in fold_models:\n            model.eval()\n            outputs = model(image)\n            print(outputs)\n            all_outputs.append(outputs)\n            ensemble_outputs.append(torch.stack(all_outputs).mean(dim=0))\n        \nensemble_outputs = torch.cat(ensemble_outputs, dim=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:46:07.181824Z","iopub.execute_input":"2025-11-26T18:46:07.182322Z","iopub.status.idle":"2025-11-26T18:46:07.782447Z","shell.execute_reply.started":"2025-11-26T18:46:07.182295Z","shell.execute_reply":"2025-11-26T18:46:07.781550Z"}},"outputs":[{"name":"stdout","text":"(tensor([[0.4832, 0.6633, 0.6894],\n        [0.4832, 0.6633, 0.6894],\n        [0.4832, 0.6633, 0.6894],\n        [0.4832, 0.6633, 0.6894],\n        [0.4832, 0.6633, 0.6894]], device='cuda:0'), tensor([[ 0.2535,  0.3230, -0.2218, -0.2500, -0.0024],\n        [ 0.2535,  0.3230, -0.2218, -0.2500, -0.0024],\n        [ 0.2535,  0.3230, -0.2218, -0.2500, -0.0024],\n        [ 0.2535,  0.3230, -0.2218, -0.2500, -0.0024],\n        [ 0.2535,  0.3230, -0.2218, -0.2500, -0.0024]], device='cuda:0'))\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/906939112.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mensemble_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mensemble_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got tuple"],"ename":"TypeError","evalue":"expected Tensor as element 0 in argument 0, but got tuple","output_type":"error"}],"execution_count":320},{"cell_type":"code","source":"test_dataset = BiomassDataset(test_df, base_path, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n\n# Dictionary to store predictions grouped by image_path\npreds_by_image = defaultdict(list)\n\nwith torch.no_grad():\n    for image, img_paths in test_loader:\n        image = image.to(device)\n        \n        # Get ensemble predictions from all models\n        all_outputs = []\n        for model in fold_models:\n            model.eval()\n            outputs = model(image)\n            all_outputs.append(outputs)\n        \n        # Average across models (ensemble)\n        # ensemble_batch = torch.stack(all_outputs).mean(dim=0)  # [batch_size, 5]\n        # Collect regression and binary outputs separately\n        all_regression = [out[1] for out in all_outputs]  # regression head\n        all_binary = [out[0] for out in all_outputs]      # binary head\n        \n        # Ensemble (average) across models\n        ensemble_regression = torch.stack(all_regression).mean(dim=0)  # [batch_size, 5]\n        ensemble_binary = torch.stack(all_binary).mean(dim=0)          # [batch_size, 3]\n        \n        # Create final predictions\n        final_preds = ensemble_regression.clone()\n        \n        # Apply hurdle logic for first 3 columns\n        final_preds[:, :3] *= (ensemble_binary > 0.5).float()  # zero if binary predicts 0\n        \n        # Last 2 columns remain as regression outputs\n        # Group predictions by image_path\n        # Since BiomassDataset returns 2 items per image (left/right halves),\n        # img_paths is a tuple/list of image paths (may have duplicates)\n        # We group by image_path and will average left/right later\n        batch_size = ensemble_batch.shape[0]\n        for i in range(batch_size):\n            img_path = img_paths[i]  # Get the image_path for this batch item\n            preds_by_image[img_path].append(ensemble_batch[i].cpu())\n\n# Average left/right predictions for each image\nimage_predictions = {}\nfor img_path, preds in preds_by_image.items():\n    # Stack and average: [num_halves, 5] -> [5]\n    # Each image should have exactly 2 predictions (left + right)\n    stacked_preds = torch.stack(preds)  # [2, 5] for left and right halves\n    image_predictions[img_path] = stacked_preds.mean(dim=0)  # Average to [5]ee\n\n# Check predictions for first image\nif len(image_predictions) > 0:\n    first_img_path = list(image_predictions.keys())[0]\n    print(f\"Image: {first_img_path}\")\n    print(f\"Predictions: {image_predictions[first_img_path].tolist()}\")\n    print(f\"Target columns: {TARGET_COLS}\")\nelse:\n    print(\"No predictions available yet. Run the test prediction cell first.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:46:14.903159Z","iopub.execute_input":"2025-11-26T18:46:14.903716Z","iopub.status.idle":"2025-11-26T18:46:15.226664Z","shell.execute_reply.started":"2025-11-26T18:46:14.903688Z","shell.execute_reply":"2025-11-26T18:46:15.225735Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2056023370.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Average across models (ensemble)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mensemble_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, 5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Group predictions by image_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got tuple"],"ename":"TypeError","evalue":"expected Tensor as element 0 in argument 0, but got tuple","output_type":"error"}],"execution_count":321},{"cell_type":"code","source":"# Denormalize all predictions back to original scale\nfor img_path in image_predictions:\n    image_predictions[img_path] = denormalize_targets(image_predictions[img_path])\n\nprint(f\"Denormalized predictions for {len(image_predictions)} images\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:42:44.228615Z","iopub.status.idle":"2025-11-26T18:42:44.228817Z","shell.execute_reply.started":"2025-11-26T18:42:44.228721Z","shell.execute_reply":"2025-11-26T18:42:44.228730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_outputs[0].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:42:44.229491Z","iopub.status.idle":"2025-11-26T18:42:44.229714Z","shell.execute_reply.started":"2025-11-26T18:42:44.229616Z","shell.execute_reply":"2025-11-26T18:42:44.229625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.read_csv(submission_path)\n\nfor i, row in submission_df.iterrows():\n    img_path = test_df[test_df['sample_id'] == row['sample_id']]['image_path'].values[0]\n    target_name = test_df[test_df['sample_id'] == row['sample_id']]['target_name'].values[0]\n    \n    preds = ensemble_outputs\n    target_idx = TARGET_COLS.index(target_name)\n    submission_df.at[i, 'target'] = ensemble_outputs[i, target_idx].item()\n\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:42:44.231106Z","iopub.status.idle":"2025-11-26T18:42:44.231459Z","shell.execute_reply.started":"2025-11-26T18:42:44.231316Z","shell.execute_reply":"2025-11-26T18:42:44.231327Z"}},"outputs":[],"execution_count":null}]}