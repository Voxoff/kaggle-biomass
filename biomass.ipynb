{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":1803569,"sourceType":"datasetVersion","datasetId":1071580},{"sourceId":653332,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":493548,"modelId":508969}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import os\nSET_SEED=42\nos.environ['PYTHONHASHSEED'] = str(SET_SEED)\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:37.458318Z","iopub.execute_input":"2025-11-20T15:33:37.458678Z","iopub.status.idle":"2025-11-20T15:33:37.462524Z","shell.execute_reply.started":"2025-11-20T15:33:37.458657Z","shell.execute_reply":"2025-11-20T15:33:37.461836Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport copy\nimport sklearn\nimport gc\nimport time\nimport timm\nimport random\nimport safetensors\nfrom safetensors.torch import load_file\nfrom PIL import Image\nfrom torch.utils.data import DataLoader\nfrom sklearn.preprocessing import StandardScaler\nfrom torchvision import transforms\nfrom torchvision import models\nfrom collections import defaultdict\nfrom sklearn.model_selection import GroupKFold\nfrom torch.utils.data import random_split\nfrom scipy.stats import zscore\nif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') != 'Batch':\n    !pip install -q ipdb\n    import ipdb","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:37.482892Z","iopub.execute_input":"2025-11-20T15:33:37.483088Z","iopub.status.idle":"2025-11-20T15:33:40.621396Z","shell.execute_reply.started":"2025-11-20T15:33:37.483073Z","shell.execute_reply":"2025-11-20T15:33:40.620577Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"\ndef set_seed(seed=SET_SEED, disable_list=['cuda_block']):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    if 'cuda_block' not in disable_list: # stuck when train deberta\n            os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n    try:\n        torch.use_deterministic_algorithms(True, warn_only=True)\n    except AttributeError:\n        pass  # Older PyTorch versions\n    \n\n\nset_seed(SET_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.623098Z","iopub.execute_input":"2025-11-20T15:33:40.623311Z","iopub.status.idle":"2025-11-20T15:33:40.630782Z","shell.execute_reply.started":"2025-11-20T15:33:40.623289Z","shell.execute_reply":"2025-11-20T15:33:40.630201Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Hyperparameters\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBATCH_SIZE = 8\nNUM_FT_EPOCHS = 20\nNUM_BB_EPOCHS = 12\nLEARNING_RATE = 0.0001\nWEIGHT_DECAY = 1e-7\nNUM_FOLDS = 3\nGIVEN_WEIGHTS = [0.1, 0.1, 0.1, 0.5, 0.2]\nTARGET_COLS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\nBASE_MODEL='resnet50'\nIMAGE_SIZE=(384,384)\nTRAIN_SHUFFLE=0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.631467Z","iopub.execute_input":"2025-11-20T15:33:40.631727Z","iopub.status.idle":"2025-11-20T15:33:40.646263Z","shell.execute_reply.started":"2025-11-20T15:33:40.631705Z","shell.execute_reply":"2025-11-20T15:33:40.645530Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def print_result(train_loss, val_loss, epoch_start, epoch, num_epochs, val_r2):\n    epoch_time = time.time() - epoch_start\n    mins, secs = divmod(epoch_time, 60)\n    \n    print(f'Epoch {epoch+1}/{num_epochs} - '\n          f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} | '\n          f'R²: {val_r2:.4f} | '\n          f'Time: {int(mins)}m {int(secs)}s')\n\nclass BiomassDataset(torch.utils.data.Dataset):\n    def __init__(self, df, base_path, transform=None):\n        self.df = df\n        self.base_path = base_path\n        self.transform = transform\n        self.target_cols = TARGET_COLS\n        self.is_training = all(col in df.columns for col in self.target_cols)\n    \n    def __len__(self):\n        return len(self.df) * 2\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx // 2] \n        img_path = os.path.join(self.base_path, row['image_path'])\n        \n        image = Image.open(img_path).convert('RGB')\n        \n        half = idx % 2\n        width, height = image.size\n        if half == 0:\n            image = image.crop((0, 0, width // 2, height))  # Left half\n        else:\n            image = image.crop((width // 2, 0, width, height))  # Right half\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_training:\n            targets = row[self.target_cols].values.astype('float32')\n            targets_normalized = (targets - TARGET_MEANS.numpy()) / TARGET_STDS.numpy()\n            \n            return image, torch.tensor(targets_normalized, dtype=torch.float32)\n        else:            \n            return image, row['image_path']\n\nclass ExtraDataset(torch.utils.data.Dataset):\n    def __init__(self, df, img_path, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_path = img_path\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_file = os.path.join(self.img_path, row['image_file_name'])\n        image = Image.open(img_file).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        target = torch.tensor(row['dry_total'], dtype=torch.float32)\n        return image, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.647720Z","iopub.execute_input":"2025-11-20T15:33:40.647922Z","iopub.status.idle":"2025-11-20T15:33:40.667242Z","shell.execute_reply.started":"2025-11-20T15:33:40.647907Z","shell.execute_reply":"2025-11-20T15:33:40.666686Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class PreTrainModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        model = timm.create_model(BASE_MODEL, pretrained=True, num_classes=0)\n        \n        ckpt_path = \"/kaggle/input/m/voxoff/resnet50/pytorch/default/1/model.safetensors\"\n        # model.load_state_dict(load_file(ckpt_path))\n\n\n        loaded_state_dict = load_file(ckpt_path)\n\n        new_state_dict = {}\n        for k, v in loaded_state_dict.items():\n            # Assuming the actual ResNet backbone weights are nested under 'resnet.encoder.'\n            if k.startswith('resnet.encoder.'):\n                new_key = k[len('resnet.encoder.'):] # Strip the prefix\n                new_state_dict[new_key] = v\n\n        # Load the modified state dict, allowing for non-matching keys (strict=False)\n        model.load_state_dict(new_state_dict, strict=False)\n\n        \n        self.backbone = model\n        in_features = self.backbone.num_features\n        \n        self.regression_head = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.regression_head(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.667967Z","iopub.execute_input":"2025-11-20T15:33:40.668244Z","iopub.status.idle":"2025-11-20T15:33:40.689331Z","shell.execute_reply.started":"2025-11-20T15:33:40.668215Z","shell.execute_reply":"2025-11-20T15:33:40.688695Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class FinetuneModel(nn.Module):\n    def __init__(self, pretrained_backbone):\n        super().__init__()\n        self.backbone = timm.create_model(BASE_MODEL, pretrained=False, num_classes=0)\n        in_features = self.backbone.num_features\n        \n        self.regression_head = nn.Sequential(\n            nn.Linear(in_features, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 5) # 5 outputs for competition\n        )\n\n        self._init_head_weights()\n    \n    def _init_head_weights(self):\n        \"\"\"Initialize regression head with deterministic weights\"\"\"\n        for m in self.regression_head.modules():\n            if isinstance(m, nn.Linear):\n                # Use a fixed seed for weight initialization\n                with torch.random.fork_rng():\n                    torch.manual_seed(SET_SEED)\n                    torch.nn.init.xavier_uniform_(m.weight)\n                    if m.bias is not None:\n                        torch.nn.init.zeros_(m.bias)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.regression_head(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.690080Z","iopub.execute_input":"2025-11-20T15:33:40.690316Z","iopub.status.idle":"2025-11-20T15:33:40.703718Z","shell.execute_reply.started":"2025-11-20T15:33:40.690294Z","shell.execute_reply":"2025-11-20T15:33:40.703170Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"base = '/kaggle/input'\ntrain_csv = f'{base}/csiro-biomass/train.csv'\ntest_csv = f'{base}/csiro-biomass/test.csv'\nextra_csv = f'{base}/grassclover-dataset/biomass_data/train/biomass_train_data.csv'\nextra_img = f'{base}/grassclover-dataset/biomass_data/train/images'\nbase_path = f'{base}/csiro-biomass/'\nsubmission_path = f'{base}/csiro-biomass/sample_submission.csv'\n\ndataset_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\nextra_df = pd.read_csv(extra_csv, sep=';')\nextra_img_path = extra_img\nunique_test_images = test_df['image_path'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.704402Z","iopub.execute_input":"2025-11-20T15:33:40.704652Z","iopub.status.idle":"2025-11-20T15:33:40.739791Z","shell.execute_reply.started":"2025-11-20T15:33:40.704601Z","shell.execute_reply":"2025-11-20T15:33:40.739272Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"dataset_df['Sampling_Date'] = pd.to_datetime(dataset_df['Sampling_Date'], format='mixed')  # adjust format if needed\ndataset_df = dataset_df.pivot(\n    index=['image_path','Sampling_Date'],\n    columns='target_name',\n    values='target'\n).reset_index()\ndataset_df['Month'] = dataset_df['Sampling_Date'].dt.month","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.740451Z","iopub.execute_input":"2025-11-20T15:33:40.740747Z","iopub.status.idle":"2025-11-20T15:33:40.751591Z","shell.execute_reply.started":"2025-11-20T15:33:40.740731Z","shell.execute_reply":"2025-11-20T15:33:40.751008Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def denormalize_targets(normalized_targets):\n    \"\"\"\n    Convert normalized targets back to original scale.\n    \n    Args:\n        normalized_targets: Tensor of shape [batch_size, 5] or [5] with normalized values\n    \n    Returns:\n        Tensor of same shape with denormalized values\n    \"\"\"\n    if normalized_targets.dim() == 1:\n        # Single sample: [5]\n        means = TARGET_MEANS.to(normalized_targets.device)\n        stds = TARGET_STDS.to(normalized_targets.device)\n        return normalized_targets * stds + means\n    else:\n        # Batch: [batch_size, 5]\n        means = TARGET_MEANS.to(normalized_targets.device).unsqueeze(0)  # [1, 5]\n        stds = TARGET_STDS.to(normalized_targets.device).unsqueeze(0)  # [1, 5]\n        return normalized_targets * stds + means\n\n\n# Normalization\ntarget_stats = {}\nfor col in TARGET_COLS:\n    target_stats[col] = {\n        'mean': dataset_df[col].mean(),\n        'std': dataset_df[col].std() + 1e-8\n    }\n    print(f\"{col}: mean={target_stats[col]['mean']:.2f}, std={target_stats[col]['std']:.2f}\")\n\n# Store for later denormalization\nTARGET_MEANS = torch.tensor([target_stats[col]['mean'] for col in TARGET_COLS], dtype=torch.float32)\nTARGET_STDS = torch.tensor([target_stats[col]['std'] for col in TARGET_COLS], dtype=torch.float32)\n\ndataset_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.752291Z","iopub.execute_input":"2025-11-20T15:33:40.752595Z","iopub.status.idle":"2025-11-20T15:33:40.785423Z","shell.execute_reply.started":"2025-11-20T15:33:40.752572Z","shell.execute_reply":"2025-11-20T15:33:40.784746Z"}},"outputs":[{"name":"stdout","text":"Dry_Clover_g: mean=6.65, std=12.12\nDry_Dead_g: mean=12.04, std=12.40\nDry_Green_g: mean=26.62, std=25.40\nDry_Total_g: mean=45.32, std=27.98\nGDM_g: mean=33.27, std=24.94\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"target_name              image_path Sampling_Date  Dry_Clover_g  Dry_Dead_g  \\\n0            train/ID1011485656.jpg    2015-09-04        0.0000     31.9984   \n1            train/ID1012260530.jpg    2015-04-01        0.0000      0.0000   \n2            train/ID1025234388.jpg    2015-09-01        6.0500      0.0000   \n3            train/ID1028611175.jpg    2015-05-18        0.0000     30.9703   \n4            train/ID1035947949.jpg    2015-09-11        0.4343     23.2239   \n\ntarget_name  Dry_Green_g  Dry_Total_g    GDM_g  Month  \n0                16.2751      48.2735  16.2750      9  \n1                 7.6000       7.6000   7.6000      4  \n2                 0.0000       6.0500   6.0500      9  \n3                24.2376      55.2079  24.2376      5  \n4                10.5261      34.1844  10.9605      9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target_name</th>\n      <th>image_path</th>\n      <th>Sampling_Date</th>\n      <th>Dry_Clover_g</th>\n      <th>Dry_Dead_g</th>\n      <th>Dry_Green_g</th>\n      <th>Dry_Total_g</th>\n      <th>GDM_g</th>\n      <th>Month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015-09-04</td>\n      <td>0.0000</td>\n      <td>31.9984</td>\n      <td>16.2751</td>\n      <td>48.2735</td>\n      <td>16.2750</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train/ID1012260530.jpg</td>\n      <td>2015-04-01</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>7.6000</td>\n      <td>7.6000</td>\n      <td>7.6000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train/ID1025234388.jpg</td>\n      <td>2015-09-01</td>\n      <td>6.0500</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>6.0500</td>\n      <td>6.0500</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train/ID1028611175.jpg</td>\n      <td>2015-05-18</td>\n      <td>0.0000</td>\n      <td>30.9703</td>\n      <td>24.2376</td>\n      <td>55.2079</td>\n      <td>24.2376</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train/ID1035947949.jpg</td>\n      <td>2015-09-11</td>\n      <td>0.4343</td>\n      <td>23.2239</td>\n      <td>10.5261</td>\n      <td>34.1844</td>\n      <td>10.9605</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"### Pytorch","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    # transforms.RandomHorizontalFlip(p=0.5),\n    # transforms.RandomVerticalFlip(p=0.5),\n    # transforms.RandomRotation(15),\n    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                       std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                       std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.787666Z","iopub.execute_input":"2025-11-20T15:33:40.787853Z","iopub.status.idle":"2025-11-20T15:33:40.792441Z","shell.execute_reply.started":"2025-11-20T15:33:40.787838Z","shell.execute_reply":"2025-11-20T15:33:40.791768Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"### Support Functions","metadata":{}},{"cell_type":"code","source":"def forward_pass(images, targets, optimizer, model, validation=False):\n    images = images.to(device)\n    targets = targets.to(device)\n    \n    if not validation: \n        optimizer.zero_grad()\n    \n    outputs = model(images)\n    \n    loss = combined_biomass_loss(outputs, targets)\n    \n    if not validation:\n        loss.backward()\n        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n    \n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.793235Z","iopub.execute_input":"2025-11-20T15:33:40.793537Z","iopub.status.idle":"2025-11-20T15:33:40.812254Z","shell.execute_reply.started":"2025-11-20T15:33:40.793489Z","shell.execute_reply":"2025-11-20T15:33:40.811501Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"### Train Model","metadata":{"execution":{"iopub.status.busy":"2025-11-14T12:22:03.521564Z","iopub.status.idle":"2025-11-14T12:22:03.522083Z","shell.execute_reply":"2025-11-14T12:22:03.521846Z","shell.execute_reply.started":"2025-11-14T12:22:03.521827Z"}}},{"cell_type":"code","source":"def combined_biomass_loss(biomass_pred, biomass_true):\n    weights = torch.tensor(GIVEN_WEIGHTS, device=biomass_pred.device)\n\n    smooth_l1 = nn.SmoothL1Loss(reduction='none')\n    mse = nn.MSELoss(reduction='none')\n    \n    smooth_l1_loss = smooth_l1(biomass_pred, biomass_true)\n    mse_loss = mse(biomass_pred, biomass_true)\n    \n    combined = 0.3 * smooth_l1_loss + 0.7 * mse_loss\n    weighted_loss = (combined * weights).mean()\n    \n    return weighted_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.813067Z","iopub.execute_input":"2025-11-20T15:33:40.813386Z","iopub.status.idle":"2025-11-20T15:33:40.828871Z","shell.execute_reply.started":"2025-11-20T15:33:40.813368Z","shell.execute_reply":"2025-11-20T15:33:40.828214Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def weighted_r2_score(sum_target, total_samples, sum_target_sq, ss_res):\n    mean_target = sum_target / total_samples\n    ss_tot = sum_target_sq - total_samples * (mean_target ** 2)\n\n    r2_per_output = 1 - ss_res / (ss_tot + 1e-10)\n\n    weights = torch.tensor(GIVEN_WEIGHTS, device=device)\n    r2_weighted = (r2_per_output * weights).sum() / weights.sum()\n    return r2_weighted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.829630Z","iopub.execute_input":"2025-11-20T15:33:40.829885Z","iopub.status.idle":"2025-11-20T15:33:40.843157Z","shell.execute_reply.started":"2025-11-20T15:33:40.829855Z","shell.execute_reply":"2025-11-20T15:33:40.842559Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def pretrain_phase(extra_df, extra_img_path, num_epochs=NUM_FT_EPOCHS):\n    print(\"=\" * 50)\n    print(\"PHASE 1: PRE-TRAINING ON EXTRA DATASET\")\n    \n    # Create dataset\n    extra_dataset = ExtraDataset(extra_df, extra_img_path, transform=train_transform)\n\n    generator = torch.Generator().manual_seed(SET_SEED)\n    \n    extra_train_size = int(0.8 * len(extra_dataset))\n    extra_dev_size = len(extra_dataset) - extra_train_size\n\n    extra_train_dataset, extra_dev_dataset = random_split(extra_dataset, [extra_train_size, extra_dev_size], generator=generator)\n\n    extra_loader = DataLoader(extra_train_dataset, batch_size=16, shuffle=TRAIN_SHUFFLE)\n    extra_dev_loader = DataLoader(extra_dev_dataset, batch_size=16, shuffle=False)  # usually no shuffle for dev\n    \n    # Initialize model\n    model = PreTrainModel().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    criterion = nn.SmoothL1Loss()\n    \n    gc.collect()\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        for images, targets in extra_loader:\n            images, targets = images.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images).squeeze()\n            loss = criterion(outputs, targets)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            total_loss += loss.item()\n            # validate_epoch(model, extra_dev_loader, criterion=criterion)\n        \n        print(f\"Pre-train Epoch {epoch+1}/{num_epochs} - Loss: {total_loss/len(extra_loader):.4f}\")\n    \n    return model.backbone ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.843820Z","iopub.execute_input":"2025-11-20T15:33:40.844029Z","iopub.status.idle":"2025-11-20T15:33:40.857172Z","shell.execute_reply.started":"2025-11-20T15:33:40.844006Z","shell.execute_reply":"2025-11-20T15:33:40.856548Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def create_data_loaders(train_df, val_df, batch_size=BATCH_SIZE):\n    train_dataset = BiomassDataset(train_df, base_path, transform=train_transform)\n    val_dataset = BiomassDataset(val_df, base_path, transform=val_transform)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=TRAIN_SHUFFLE, num_workers=0)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n    return train_loader, val_loader\n\ndef train_epoch(model, train_loader, optimizer, quick):\n    model.train()\n    total_loss = 0\n    for i, (images, targets) in enumerate(train_loader):\n        if quick and i >= 1:\n            break\n            \n        loss = forward_pass(images, targets, optimizer, model)\n        total_loss += loss.item()\n    return total_loss / len(train_loader)\n\ndef validate_epoch(model, val_loader, criterion=None):\n    model.eval()\n    total_loss = 0\n    total_samples = 0\n\n    # Accumulate sums for R² calculation (no need to store all predictions)\n    ss_res = torch.zeros(5, device=device)\n    sum_target = torch.zeros(5, device=device)\n    sum_target_sq = torch.zeros(5, device=device)\n\n    with torch.no_grad():\n        for images, targets in val_loader:\n            images = images.to(device)\n            targets = targets.to(device)\n            \n            outputs = model(images)\n\n            if criterion:\n                loss = criterion(outputs, targets)\n            else:\n                loss = combined_biomass_loss(outputs, targets)\n            \n            total_loss += loss.item()\n            total_samples += outputs.shape[0] # batch_size\n            \n            outputs_denorm = denormalize_targets(outputs)\n            targets_denorm = denormalize_targets(targets)\n            \n            ss_res += ((outputs_denorm - targets_denorm) ** 2).sum(dim=0)\n            sum_target += targets_denorm.sum(dim=0)\n            sum_target_sq += (targets_denorm ** 2).sum(dim=0)\n\n    r2_weighted = weighted_r2_score(sum_target, total_samples, sum_target_sq, ss_res)\n\n    return total_loss / len(val_loader), r2_weighted\n\ndef finetune_phase(pretrained_backbone, num_epochs=NUM_FT_EPOCHS, quick=False):\n    print(\"\\n\" + \"=\" * 50)\n    print(\"PHASE 2: FINE-TUNING ON COMPETITION DATA\")\n    \n    r2 = []\n\n    for fold, (train_idx, val_idx) in enumerate(splits):\n        print(f'\\n--- Fold {fold + 1}/{NUM_FOLDS} ---')\n        \n        train_df = dataset_df.iloc[train_idx].copy()\n        val_df = dataset_df.iloc[val_idx].copy()\n        train_loader, val_loader = create_data_loaders(train_df, val_df)\n\n        model = FinetuneModel(copy.deepcopy(pretrained_backbone)).to(device)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        \n        for epoch in range(num_epochs):\n            epoch_start = time.time()\n            train_loss = train_epoch(model, train_loader, optimizer, quick)\n            val_loss, val_r2 = validate_epoch(model, val_loader)\n            \n            print_result(train_loss, val_loss, epoch_start, epoch, num_epochs, val_r2)\n\n        r2.append(val_r2.item())\n        fold_models.append(model)\n        print(f'Fold {fold + 1} complete!')\n\n    overall_r2 = np.array(r2).mean()\n    \n    print(f'\\nOverall R² across all folds: {overall_r2:.4f}')\n\n    return fold_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:33:40.857753Z","iopub.execute_input":"2025-11-20T15:33:40.857975Z","iopub.status.idle":"2025-11-20T15:33:40.876701Z","shell.execute_reply.started":"2025-11-20T15:33:40.857956Z","shell.execute_reply":"2025-11-20T15:33:40.876044Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"pretrained_backbone = pretrain_phase(extra_df, extra_img_path, num_epochs=1)","metadata":{"execution":{"iopub.status.busy":"2025-11-20T15:33:40.877350Z","iopub.execute_input":"2025-11-20T15:33:40.877584Z","iopub.status.idle":"2025-11-20T15:34:20.202980Z","shell.execute_reply.started":"2025-11-20T15:33:40.877562Z","shell.execute_reply":"2025-11-20T15:34:20.202299Z"},"trusted":true,"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"==================================================\nPHASE 1: PRE-TRAINING ON EXTRA DATASET\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8515f3aa294629b20b85b72374e732"}},"metadata":{}},{"name":"stdout","text":"Pre-train Epoch 1/1 - Loss: 65.7171\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"### NUM_FOLDS\n# NUM_FT_EPOCHS\nkfold = GroupKFold(n_splits=NUM_FOLDS)\ngroups = dataset_df['Month']\nsplits = kfold.split(dataset_df, groups=groups)\nfold_models = []\nfinal_model = finetune_phase(pretrained_backbone, num_epochs=40, quick=False)\n# Epoch 1/40 - Train Loss: 0.1655, Val Loss: 0.1425 | R²: 0.1264 | Time: 1m 2s","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:47:48.045084Z","iopub.execute_input":"2025-11-20T15:47:48.045710Z","iopub.status.idle":"2025-11-20T16:17:20.309586Z","shell.execute_reply.started":"2025-11-20T15:47:48.045685Z","shell.execute_reply":"2025-11-20T16:17:20.308554Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nPHASE 2: FINE-TUNING ON COMPETITION DATA\n\n--- Fold 1/3 ---\nEpoch 1/40 - Train Loss: 0.1652, Val Loss: 0.1259 | R²: 0.2431 | Time: 0m 55s\nEpoch 2/40 - Train Loss: 0.1511, Val Loss: 0.1315 | R²: 0.2047 | Time: 0m 55s\nEpoch 3/40 - Train Loss: 0.1436, Val Loss: 0.1333 | R²: 0.1948 | Time: 0m 55s\nEpoch 4/40 - Train Loss: 0.1381, Val Loss: 0.1357 | R²: 0.1824 | Time: 0m 55s\nEpoch 5/40 - Train Loss: 0.1353, Val Loss: 0.1308 | R²: 0.2074 | Time: 0m 55s\nEpoch 6/40 - Train Loss: 0.1306, Val Loss: 0.1388 | R²: 0.1503 | Time: 0m 54s\nEpoch 7/40 - Train Loss: 0.1273, Val Loss: 0.1262 | R²: 0.2445 | Time: 0m 55s\nEpoch 8/40 - Train Loss: 0.1217, Val Loss: 0.1372 | R²: 0.1848 | Time: 0m 55s\nEpoch 9/40 - Train Loss: 0.1191, Val Loss: 0.1293 | R²: 0.2434 | Time: 0m 54s\nEpoch 10/40 - Train Loss: 0.1124, Val Loss: 0.1345 | R²: 0.2079 | Time: 0m 55s\nEpoch 11/40 - Train Loss: 0.1065, Val Loss: 0.1391 | R²: 0.2027 | Time: 0m 54s\nEpoch 12/40 - Train Loss: 0.0994, Val Loss: 0.1412 | R²: 0.1812 | Time: 0m 54s\nEpoch 13/40 - Train Loss: 0.0937, Val Loss: 0.1774 | R²: -0.0138 | Time: 0m 54s\nEpoch 14/40 - Train Loss: 0.0805, Val Loss: 0.1794 | R²: -0.0653 | Time: 0m 54s\nEpoch 15/40 - Train Loss: 0.0789, Val Loss: 0.1580 | R²: 0.0672 | Time: 0m 54s\nEpoch 16/40 - Train Loss: 0.0695, Val Loss: 0.1583 | R²: 0.0741 | Time: 0m 54s\nEpoch 17/40 - Train Loss: 0.0642, Val Loss: 0.1681 | R²: -0.0577 | Time: 0m 54s\nEpoch 18/40 - Train Loss: 0.0608, Val Loss: 0.1749 | R²: -0.0776 | Time: 0m 54s\nEpoch 19/40 - Train Loss: 0.0598, Val Loss: 0.1580 | R²: 0.0292 | Time: 0m 54s\nEpoch 20/40 - Train Loss: 0.0593, Val Loss: 0.1421 | R²: 0.1642 | Time: 0m 54s\nEpoch 21/40 - Train Loss: 0.0547, Val Loss: 0.1486 | R²: 0.1299 | Time: 0m 54s\nEpoch 22/40 - Train Loss: 0.0580, Val Loss: 0.1817 | R²: -0.0487 | Time: 0m 55s\nEpoch 23/40 - Train Loss: 0.0502, Val Loss: 0.1545 | R²: 0.0486 | Time: 0m 54s\nEpoch 24/40 - Train Loss: 0.0529, Val Loss: 0.1499 | R²: 0.1361 | Time: 0m 54s\nEpoch 25/40 - Train Loss: 0.0478, Val Loss: 0.1411 | R²: 0.1691 | Time: 0m 55s\nEpoch 26/40 - Train Loss: 0.0460, Val Loss: 0.1480 | R²: 0.1305 | Time: 0m 56s\nEpoch 27/40 - Train Loss: 0.0483, Val Loss: 0.1482 | R²: 0.0975 | Time: 0m 55s\nEpoch 28/40 - Train Loss: 0.0451, Val Loss: 0.1585 | R²: 0.0400 | Time: 0m 55s\nEpoch 29/40 - Train Loss: 0.0445, Val Loss: 0.1583 | R²: 0.0654 | Time: 0m 55s\nEpoch 30/40 - Train Loss: 0.0475, Val Loss: 0.1496 | R²: 0.0865 | Time: 0m 54s\nEpoch 31/40 - Train Loss: 0.0449, Val Loss: 0.1621 | R²: -0.0097 | Time: 0m 55s\nEpoch 32/40 - Train Loss: 0.0430, Val Loss: 0.1598 | R²: 0.0450 | Time: 0m 54s\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/548061177.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfold_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_backbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquick\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Epoch 1/40 - Train Loss: 0.1655, Val Loss: 0.1425 | R²: 0.1264 | Time: 1m 2s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/1250515272.py\u001b[0m in \u001b[0;36mfinetune_phase\u001b[0;34m(pretrained_backbone, num_epochs, quick)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/1250515272.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, quick)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"test_dataset = BiomassDataset(test_df, base_path, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n\nensemble_outputs = []\nwith torch.no_grad():\n    for image, img_path in test_loader:\n        image = image.to(device)\n        \n        # Get predictions from all models\n        all_outputs = []\n        for model in fold_models:\n            model.eval()\n            outputs = model(image)\n            print(outputs)\n            all_outputs.append(outputs)\n            ensemble_outputs.append(torch.stack(all_outputs).mean(dim=0))\n        \nensemble_outputs = torch.cat(ensemble_outputs, dim=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:47:45.839557Z","iopub.status.idle":"2025-11-20T15:47:45.839821Z","shell.execute_reply.started":"2025-11-20T15:47:45.839684Z","shell.execute_reply":"2025-11-20T15:47:45.839694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = BiomassDataset(test_df, base_path, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n\n# Dictionary to store predictions grouped by image_path\npreds_by_image = defaultdict(list)\n\nwith torch.no_grad():\n    for image, img_paths in test_loader:\n        image = image.to(device)\n        \n        # Get ensemble predictions from all models\n        all_outputs = []\n        for model in fold_models:\n            model.eval()\n            outputs = model(image)\n            all_outputs.append(outputs)\n        \n        # Average across models (ensemble)\n        ensemble_batch = torch.stack(all_outputs).mean(dim=0)  # [batch_size, 5]\n        \n        # Group predictions by image_path\n        # Since BiomassDataset returns 2 items per image (left/right halves),\n        # img_paths is a tuple/list of image paths (may have duplicates)\n        # We group by image_path and will average left/right later\n        batch_size = ensemble_batch.shape[0]\n        for i in range(batch_size):\n            img_path = img_paths[i]  # Get the image_path for this batch item\n            preds_by_image[img_path].append(ensemble_batch[i].cpu())\n\n# Average left/right predictions for each image\nimage_predictions = {}\nfor img_path, preds in preds_by_image.items():\n    # Stack and average: [num_halves, 5] -> [5]\n    # Each image should have exactly 2 predictions (left + right)\n    stacked_preds = torch.stack(preds)  # [2, 5] for left and right halves\n    image_predictions[img_path] = stacked_preds.mean(dim=0)  # Average to [5]ee\n\n# Check predictions for first image\nif len(image_predictions) > 0:\n    first_img_path = list(image_predictions.keys())[0]\n    print(f\"Image: {first_img_path}\")\n    print(f\"Predictions: {image_predictions[first_img_path].tolist()}\")\n    print(f\"Target columns: {TARGET_COLS}\")\nelse:\n    print(\"No predictions available yet. Run the test prediction cell first.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:47:45.840923Z","iopub.status.idle":"2025-11-20T15:47:45.841263Z","shell.execute_reply.started":"2025-11-20T15:47:45.841089Z","shell.execute_reply":"2025-11-20T15:47:45.841104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Denormalize all predictions back to original scale\nfor img_path in image_predictions:\n    image_predictions[img_path] = denormalize_targets(image_predictions[img_path])\n\nprint(f\"Denormalized predictions for {len(image_predictions)} images\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:47:45.842013Z","iopub.status.idle":"2025-11-20T15:47:45.842305Z","shell.execute_reply.started":"2025-11-20T15:47:45.842141Z","shell.execute_reply":"2025-11-20T15:47:45.842157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_outputs[0].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:47:45.843546Z","iopub.status.idle":"2025-11-20T15:47:45.843786Z","shell.execute_reply.started":"2025-11-20T15:47:45.843684Z","shell.execute_reply":"2025-11-20T15:47:45.843694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.read_csv(submission_path)\n\nfor i, row in submission_df.iterrows():\n    img_path = test_df[test_df['sample_id'] == row['sample_id']]['image_path'].values[0]\n    target_name = test_df[test_df['sample_id'] == row['sample_id']]['target_name'].values[0]\n    \n    preds = ensemble_outputs\n    target_idx = TARGET_COLS.index(target_name)\n    submission_df.at[i, 'target'] = ensemble_outputs[i, target_idx].item()\n\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:47:45.844584Z","iopub.status.idle":"2025-11-20T15:47:45.844851Z","shell.execute_reply.started":"2025-11-20T15:47:45.844726Z","shell.execute_reply":"2025-11-20T15:47:45.844736Z"}},"outputs":[],"execution_count":null}]}