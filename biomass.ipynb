{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":1803569,"sourceType":"datasetVersion","datasetId":1071580},{"sourceId":653332,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":493548,"modelId":508969}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import os\nSET_SEED=42\nos.environ['PYTHONHASHSEED'] = str(SET_SEED)\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:56.580790Z","iopub.execute_input":"2025-11-20T17:10:56.581441Z","iopub.status.idle":"2025-11-20T17:10:56.585093Z","shell.execute_reply.started":"2025-11-20T17:10:56.581419Z","shell.execute_reply":"2025-11-20T17:10:56.584373Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport copy\nfrom torch.amp import autocast, GradScaler\nimport sklearn\nimport gc\nimport time\nimport timm\nimport random\nimport safetensors\nfrom safetensors.torch import load_file\nfrom PIL import Image\nfrom torch.utils.data import DataLoader\nfrom sklearn.preprocessing import StandardScaler\nfrom torchvision import transforms\nfrom torchvision import models\nfrom collections import defaultdict\nfrom sklearn.model_selection import GroupKFold\nfrom torch.utils.data import random_split\nfrom scipy.stats import zscore\nif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') != 'Batch':\n    !pip install -q ipdb\n    import ipdb","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:56.593033Z","iopub.execute_input":"2025-11-20T17:10:56.593450Z","iopub.status.idle":"2025-11-20T17:10:59.783582Z","shell.execute_reply.started":"2025-11-20T17:10:56.593434Z","shell.execute_reply":"2025-11-20T17:10:59.782601Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"\ndef set_seed(seed=SET_SEED, disable_list=['cuda_block']):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    if 'cuda_block' not in disable_list: # stuck when train deberta\n            os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n    try:\n        torch.use_deterministic_algorithms(True, warn_only=True)\n    except AttributeError:\n        pass  # Older PyTorch versions\n    \n\n\nset_seed(SET_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.785577Z","iopub.execute_input":"2025-11-20T17:10:59.785916Z","iopub.status.idle":"2025-11-20T17:10:59.793736Z","shell.execute_reply.started":"2025-11-20T17:10:59.785871Z","shell.execute_reply":"2025-11-20T17:10:59.793061Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# Hyperparameters\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBATCH_SIZE = 8\nNUM_FT_EPOCHS = 20\nNUM_BB_EPOCHS = 12\nLEARNING_RATE = 0.0001\nMAX_LR = 0.001  \nUSE_MIXED_PRECISION = True  # Enable mixed precision for faster training\nWEIGHT_DECAY = 1e-7\nNUM_FOLDS = 3\nGIVEN_WEIGHTS = [0.1, 0.1, 0.1, 0.5, 0.2]\nTARGET_COLS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\nBASE_MODEL='resnet50'\nIMAGE_SIZE=(384,384)\nTRAIN_SHUFFLE=0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.794465Z","iopub.execute_input":"2025-11-20T17:10:59.794715Z","iopub.status.idle":"2025-11-20T17:10:59.809740Z","shell.execute_reply.started":"2025-11-20T17:10:59.794699Z","shell.execute_reply":"2025-11-20T17:10:59.809059Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"def print_result(train_loss, val_loss, epoch_start, epoch, num_epochs, val_r2):\n    epoch_time = time.time() - epoch_start\n    mins, secs = divmod(epoch_time, 60)\n    \n    print(f'Epoch {epoch+1}/{num_epochs} - '\n          f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} | '\n          f'R²: {val_r2:.4f} | '\n          f'Time: {int(mins)}m {int(secs)}s')\n\nclass BiomassDataset(torch.utils.data.Dataset):\n    def __init__(self, df, base_path, transform=None):\n        self.df = df\n        self.base_path = base_path\n        self.transform = transform\n        self.target_cols = TARGET_COLS\n        self.is_training = all(col in df.columns for col in self.target_cols)\n    \n    def __len__(self):\n        return len(self.df) * 2\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx // 2] \n        img_path = os.path.join(self.base_path, row['image_path'])\n        \n        image = Image.open(img_path).convert('RGB')\n        \n        half = idx % 2\n        width, height = image.size\n        if half == 0:\n            image = image.crop((0, 0, width // 2, height))  # Left half\n        else:\n            image = image.crop((width // 2, 0, width, height))  # Right half\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_training:\n            targets = row[self.target_cols].values.astype('float32')\n            targets_normalized = (targets - TARGET_MEANS.numpy()) / TARGET_STDS.numpy()\n            \n            return image, torch.tensor(targets_normalized, dtype=torch.float32)\n        else:            \n            return image, row['image_path']\n\nclass ExtraDataset(torch.utils.data.Dataset):\n    def __init__(self, df, img_path, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_path = img_path\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_file = os.path.join(self.img_path, row['image_file_name'])\n        image = Image.open(img_file).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        target = torch.tensor(row['dry_total'], dtype=torch.float32)\n        return image, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.811307Z","iopub.execute_input":"2025-11-20T17:10:59.811505Z","iopub.status.idle":"2025-11-20T17:10:59.827018Z","shell.execute_reply.started":"2025-11-20T17:10:59.811491Z","shell.execute_reply":"2025-11-20T17:10:59.826471Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"class PreTrainModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        model = timm.create_model(BASE_MODEL, pretrained=True, num_classes=0)\n        \n        ckpt_path = \"/kaggle/input/m/voxoff/resnet50/pytorch/default/1/model.safetensors\"\n        # model.load_state_dict(load_file(ckpt_path))\n\n\n        loaded_state_dict = load_file(ckpt_path)\n\n        new_state_dict = {}\n        for k, v in loaded_state_dict.items():\n            # Assuming the actual ResNet backbone weights are nested under 'resnet.encoder.'\n            if k.startswith('resnet.encoder.'):\n                new_key = k[len('resnet.encoder.'):] # Strip the prefix\n                new_state_dict[new_key] = v\n\n        # Load the modified state dict, allowing for non-matching keys (strict=False)\n        model.load_state_dict(new_state_dict, strict=False)\n\n        \n        self.backbone = model\n        in_features = self.backbone.num_features\n        \n        self.regression_head = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.regression_head(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.827745Z","iopub.execute_input":"2025-11-20T17:10:59.827959Z","iopub.status.idle":"2025-11-20T17:10:59.845874Z","shell.execute_reply.started":"2025-11-20T17:10:59.827935Z","shell.execute_reply":"2025-11-20T17:10:59.845150Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"class FinetuneModel(nn.Module):\n    def __init__(self, pretrained_backbone):\n        super().__init__()\n        self.backbone = timm.create_model(BASE_MODEL, pretrained=False, num_classes=0)\n        in_features = self.backbone.num_features\n        \n        self.regression_head = nn.Sequential(\n            nn.Linear(in_features, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 5) # 5 outputs for competition\n        )\n\n        self._init_head_weights()\n    \n    def _init_head_weights(self):\n        \"\"\"Initialize regression head with deterministic weights\"\"\"\n        for m in self.regression_head.modules():\n            if isinstance(m, nn.Linear):\n                # Use a fixed seed for weight initialization\n                with torch.random.fork_rng():\n                    torch.manual_seed(SET_SEED)\n                    torch.nn.init.xavier_uniform_(m.weight)\n                    if m.bias is not None:\n                        torch.nn.init.zeros_(m.bias)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.regression_head(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.846574Z","iopub.execute_input":"2025-11-20T17:10:59.846783Z","iopub.status.idle":"2025-11-20T17:10:59.861419Z","shell.execute_reply.started":"2025-11-20T17:10:59.846768Z","shell.execute_reply":"2025-11-20T17:10:59.860715Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"base = '/kaggle/input'\ntrain_csv = f'{base}/csiro-biomass/train.csv'\ntest_csv = f'{base}/csiro-biomass/test.csv'\nextra_csv = f'{base}/grassclover-dataset/biomass_data/train/biomass_train_data.csv'\nextra_img = f'{base}/grassclover-dataset/biomass_data/train/images'\nbase_path = f'{base}/csiro-biomass/'\nsubmission_path = f'{base}/csiro-biomass/sample_submission.csv'\n\ndataset_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\nextra_df = pd.read_csv(extra_csv, sep=';')\nextra_img_path = extra_img\nunique_test_images = test_df['image_path'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.862254Z","iopub.execute_input":"2025-11-20T17:10:59.862500Z","iopub.status.idle":"2025-11-20T17:10:59.897337Z","shell.execute_reply.started":"2025-11-20T17:10:59.862479Z","shell.execute_reply":"2025-11-20T17:10:59.896787Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"dataset_df['Sampling_Date'] = pd.to_datetime(dataset_df['Sampling_Date'], format='mixed')  # adjust format if needed\ndataset_df = dataset_df.pivot(\n    index=['image_path','Sampling_Date'],\n    columns='target_name',\n    values='target'\n).reset_index()\ndataset_df['Month'] = dataset_df['Sampling_Date'].dt.month","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.898032Z","iopub.execute_input":"2025-11-20T17:10:59.898283Z","iopub.status.idle":"2025-11-20T17:10:59.910034Z","shell.execute_reply.started":"2025-11-20T17:10:59.898258Z","shell.execute_reply":"2025-11-20T17:10:59.909300Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"def denormalize_targets(normalized_targets):\n    \"\"\"\n    Convert normalized targets back to original scale.\n    \n    Args:\n        normalized_targets: Tensor of shape [batch_size, 5] or [5] with normalized values\n    \n    Returns:\n        Tensor of same shape with denormalized values\n    \"\"\"\n    if normalized_targets.dim() == 1:\n        # Single sample: [5]\n        means = TARGET_MEANS.to(normalized_targets.device)\n        stds = TARGET_STDS.to(normalized_targets.device)\n        return normalized_targets * stds + means\n    else:\n        # Batch: [batch_size, 5]\n        means = TARGET_MEANS.to(normalized_targets.device).unsqueeze(0)  # [1, 5]\n        stds = TARGET_STDS.to(normalized_targets.device).unsqueeze(0)  # [1, 5]\n        return normalized_targets * stds + means\n\n\n# Normalization\ntarget_stats = {}\nfor col in TARGET_COLS:\n    target_stats[col] = {\n        'mean': dataset_df[col].mean(),\n        'std': dataset_df[col].std() + 1e-8\n    }\n    print(f\"{col}: mean={target_stats[col]['mean']:.2f}, std={target_stats[col]['std']:.2f}\")\n\n# Store for later denormalization\nTARGET_MEANS = torch.tensor([target_stats[col]['mean'] for col in TARGET_COLS], dtype=torch.float32)\nTARGET_STDS = torch.tensor([target_stats[col]['std'] for col in TARGET_COLS], dtype=torch.float32)\n\ndataset_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.910812Z","iopub.execute_input":"2025-11-20T17:10:59.911066Z","iopub.status.idle":"2025-11-20T17:10:59.936902Z","shell.execute_reply.started":"2025-11-20T17:10:59.911045Z","shell.execute_reply":"2025-11-20T17:10:59.936155Z"}},"outputs":[{"name":"stdout","text":"Dry_Clover_g: mean=6.65, std=12.12\nDry_Dead_g: mean=12.04, std=12.40\nDry_Green_g: mean=26.62, std=25.40\nDry_Total_g: mean=45.32, std=27.98\nGDM_g: mean=33.27, std=24.94\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"target_name              image_path Sampling_Date  Dry_Clover_g  Dry_Dead_g  \\\n0            train/ID1011485656.jpg    2015-09-04        0.0000     31.9984   \n1            train/ID1012260530.jpg    2015-04-01        0.0000      0.0000   \n2            train/ID1025234388.jpg    2015-09-01        6.0500      0.0000   \n3            train/ID1028611175.jpg    2015-05-18        0.0000     30.9703   \n4            train/ID1035947949.jpg    2015-09-11        0.4343     23.2239   \n\ntarget_name  Dry_Green_g  Dry_Total_g    GDM_g  Month  \n0                16.2751      48.2735  16.2750      9  \n1                 7.6000       7.6000   7.6000      4  \n2                 0.0000       6.0500   6.0500      9  \n3                24.2376      55.2079  24.2376      5  \n4                10.5261      34.1844  10.9605      9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target_name</th>\n      <th>image_path</th>\n      <th>Sampling_Date</th>\n      <th>Dry_Clover_g</th>\n      <th>Dry_Dead_g</th>\n      <th>Dry_Green_g</th>\n      <th>Dry_Total_g</th>\n      <th>GDM_g</th>\n      <th>Month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015-09-04</td>\n      <td>0.0000</td>\n      <td>31.9984</td>\n      <td>16.2751</td>\n      <td>48.2735</td>\n      <td>16.2750</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train/ID1012260530.jpg</td>\n      <td>2015-04-01</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>7.6000</td>\n      <td>7.6000</td>\n      <td>7.6000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train/ID1025234388.jpg</td>\n      <td>2015-09-01</td>\n      <td>6.0500</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>6.0500</td>\n      <td>6.0500</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train/ID1028611175.jpg</td>\n      <td>2015-05-18</td>\n      <td>0.0000</td>\n      <td>30.9703</td>\n      <td>24.2376</td>\n      <td>55.2079</td>\n      <td>24.2376</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train/ID1035947949.jpg</td>\n      <td>2015-09-11</td>\n      <td>0.4343</td>\n      <td>23.2239</td>\n      <td>10.5261</td>\n      <td>34.1844</td>\n      <td>10.9605</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":76},{"cell_type":"markdown","source":"### Pytorch","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    # transforms.RandomHorizontalFlip(p=0.5),\n    # transforms.RandomVerticalFlip(p=0.5),\n    # transforms.RandomRotation(15),\n    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                       std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                       std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.938939Z","iopub.execute_input":"2025-11-20T17:10:59.939657Z","iopub.status.idle":"2025-11-20T17:10:59.944115Z","shell.execute_reply.started":"2025-11-20T17:10:59.939637Z","shell.execute_reply":"2025-11-20T17:10:59.943467Z"}},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":"### Support Functions","metadata":{}},{"cell_type":"code","source":"def forward_pass(images, targets, optimizer, model, validation=False, scaler=None):\n    images = images.to(device)\n    targets = targets.to(device)\n    \n    if not validation: \n        optimizer.zero_grad()\n    \n    # Use mixed precision for training\n    if not validation and USE_MIXED_PRECISION and scaler is not None:\n        with autocast('cuda'):\n            outputs = model(images)\n            loss = combined_biomass_loss(outputs, targets)\n        \n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n    else:\n        outputs = model(images)\n        loss = combined_biomass_loss(outputs, targets)\n        \n        if not validation:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n    \n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.944822Z","iopub.execute_input":"2025-11-20T17:10:59.945094Z","iopub.status.idle":"2025-11-20T17:10:59.964650Z","shell.execute_reply.started":"2025-11-20T17:10:59.945077Z","shell.execute_reply":"2025-11-20T17:10:59.963914Z"}},"outputs":[],"execution_count":78},{"cell_type":"markdown","source":"### Train Model","metadata":{"execution":{"iopub.status.busy":"2025-11-14T12:22:03.521564Z","iopub.status.idle":"2025-11-14T12:22:03.522083Z","shell.execute_reply":"2025-11-14T12:22:03.521846Z","shell.execute_reply.started":"2025-11-14T12:22:03.521827Z"}}},{"cell_type":"code","source":"def combined_biomass_loss(biomass_pred, biomass_true):\n    weights = torch.tensor(GIVEN_WEIGHTS, device=biomass_pred.device)\n\n    smooth_l1 = nn.SmoothL1Loss(reduction='none')\n    mse = nn.MSELoss(reduction='none')\n    \n    smooth_l1_loss = smooth_l1(biomass_pred, biomass_true)\n    mse_loss = mse(biomass_pred, biomass_true)\n    \n    combined = 0.3 * smooth_l1_loss + 0.7 * mse_loss\n    weighted_loss = (combined * weights).mean()\n    \n    return weighted_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.965422Z","iopub.execute_input":"2025-11-20T17:10:59.965685Z","iopub.status.idle":"2025-11-20T17:10:59.980769Z","shell.execute_reply.started":"2025-11-20T17:10:59.965669Z","shell.execute_reply":"2025-11-20T17:10:59.980064Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"def weighted_r2_score(sum_target, total_samples, sum_target_sq, ss_res):\n    mean_target = sum_target / total_samples\n    ss_tot = sum_target_sq - total_samples * (mean_target ** 2)\n\n    r2_per_output = 1 - ss_res / (ss_tot + 1e-10)\n\n    weights = torch.tensor(GIVEN_WEIGHTS, device=device)\n    r2_weighted = (r2_per_output * weights).sum() / weights.sum()\n    return r2_weighted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.981414Z","iopub.execute_input":"2025-11-20T17:10:59.981603Z","iopub.status.idle":"2025-11-20T17:10:59.997351Z","shell.execute_reply.started":"2025-11-20T17:10:59.981590Z","shell.execute_reply":"2025-11-20T17:10:59.996711Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def pretrain_phase(extra_df, extra_img_path, num_epochs=NUM_FT_EPOCHS):\n    print(\"=\" * 50)\n    print(\"PHASE 1: PRE-TRAINING ON EXTRA DATASET\")\n    \n    # Create dataset\n    extra_dataset = ExtraDataset(extra_df, extra_img_path, transform=train_transform)\n\n    generator = torch.Generator().manual_seed(SET_SEED)\n    \n    extra_train_size = int(0.8 * len(extra_dataset))\n    extra_dev_size = len(extra_dataset) - extra_train_size\n\n    extra_train_dataset, extra_dev_dataset = random_split(extra_dataset, [extra_train_size, extra_dev_size], generator=generator)\n\n    extra_loader = DataLoader(extra_train_dataset, batch_size=16, shuffle=TRAIN_SHUFFLE)\n    extra_dev_loader = DataLoader(extra_dev_dataset, batch_size=16, shuffle=False)  # usually no shuffle for dev\n    \n    # Initialize model\n    model = PreTrainModel().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    criterion = nn.SmoothL1Loss()\n    \n    gc.collect()\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        for images, targets in extra_loader:\n            images, targets = images.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images).squeeze()\n            loss = criterion(outputs, targets)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            total_loss += loss.item()\n            # validate_epoch(model, extra_dev_loader, criterion=criterion)\n        \n        print(f\"Pre-train Epoch {epoch+1}/{num_epochs} - Loss: {total_loss/len(extra_loader):.4f}\")\n    \n    return model.backbone ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:10:59.997950Z","iopub.execute_input":"2025-11-20T17:10:59.998203Z","iopub.status.idle":"2025-11-20T17:11:00.019035Z","shell.execute_reply.started":"2025-11-20T17:10:59.998187Z","shell.execute_reply":"2025-11-20T17:11:00.018307Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"def create_data_loaders(train_df, val_df, batch_size=BATCH_SIZE):\n    train_dataset = BiomassDataset(train_df, base_path, transform=train_transform)\n    val_dataset = BiomassDataset(val_df, base_path, transform=val_transform)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=TRAIN_SHUFFLE, num_workers=0, generator=loader_generator)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, generator=loader_generator)\n    return train_loader, val_loader\n\ndef train_epoch(model, train_loader, optimizer, quick, scaler=None, scheduler=None):\n    model.train()\n    total_loss = 0\n    num_batches = 0\n    for i, (images, targets) in enumerate(train_loader):\n        loss = forward_pass(images, targets, optimizer, model, validation=False, scaler=scaler)\n        total_loss += loss.item()\n        num_batches += 1\n        \n        # Step scheduler after each batch (OneCycleLR requires per-batch updates)\n        if scheduler is not None:\n            scheduler.step()\n    \n    return total_loss / num_batches if num_batches > 0 else 0.0\n\ndef validate_epoch(model, val_loader, criterion=None):\n    model.eval()\n    total_loss = 0\n    total_samples = 0\n\n    # Accumulate sums for R² calculation (no need to store all predictions)\n    ss_res = torch.zeros(5, device=device)\n    sum_target = torch.zeros(5, device=device)\n    sum_target_sq = torch.zeros(5, device=device)\n\n    with torch.no_grad():\n        for images, targets in val_loader:\n            images = images.to(device)\n            targets = targets.to(device)\n            \n            outputs = model(images)\n\n            if criterion:\n                loss = criterion(outputs, targets)\n            else:\n                loss = combined_biomass_loss(outputs, targets)\n            \n            total_loss += loss.item()\n            total_samples += outputs.shape[0] # batch_size\n            \n            outputs_denorm = denormalize_targets(outputs)\n            targets_denorm = denormalize_targets(targets)\n            \n            ss_res += ((outputs_denorm - targets_denorm) ** 2).sum(dim=0)\n            sum_target += targets_denorm.sum(dim=0)\n            sum_target_sq += (targets_denorm ** 2).sum(dim=0)\n\n    r2_weighted = weighted_r2_score(sum_target, total_samples, sum_target_sq, ss_res)\n\n    return total_loss / len(val_loader), r2_weighted\n\ndef finetune_phase(pretrained_backbone=None, num_epochs=NUM_FT_EPOCHS, quick=False):\n    print(\"\\n\" + \"=\" * 50)\n    print(\"PHASE 2: FINE-TUNING ON COMPETITION DATA\")\n    print(f\"Using OneCycleLR scheduler with max_lr={MAX_LR}\")\n    print(f\"Mixed precision: {USE_MIXED_PRECISION}\")\n    \n    r2 = []\n\n    for fold, (train_idx, val_idx) in enumerate(splits):\n        print(f'\\n--- Fold {fold + 1}/{NUM_FOLDS} ---')\n        \n        # dataset_df is already sorted, but sort again to ensure deterministic ordering\n        train_df = dataset_df.iloc[train_idx].copy().sort_values(['image_path', 'Sampling_Date']).reset_index(drop=True)\n        val_df = dataset_df.iloc[val_idx].copy().sort_values(['image_path', 'Sampling_Date']).reset_index(drop=True)\n        train_loader, val_loader = create_data_loaders(train_df, val_df)\n\n        # Use pretrained_backbone if provided, otherwise None (will use timm pretrained)\n        if pretrained_backbone is not None:\n            model = FinetuneModel(copy.deepcopy(pretrained_backbone)).to(device)\n        else:\n            model = FinetuneModel(pretrained_backbone=None).to(device)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        \n        # Calculate steps per epoch for OneCycleLR\n        steps_per_epoch = len(train_loader)\n        total_steps = steps_per_epoch * num_epochs\n        \n        # OneCycleLR scheduler for fast convergence\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=MAX_LR,\n            total_steps=total_steps,\n            pct_start=0.1,  # 10% warmup\n            anneal_strategy='cos',\n            div_factor=10.0,  # Initial LR = max_lr / div_factor\n            final_div_factor=100.0  # Final LR = initial_lr / final_div_factor\n        )\n        \n        # Mixed precision scaler\n        scaler = GradScaler('cuda') if USE_MIXED_PRECISION and device.type == 'cuda' else None\n        \n        for epoch in range(num_epochs):\n            epoch_start = time.time()\n            train_loss = train_epoch(model, train_loader, optimizer, quick, scaler=scaler, scheduler=scheduler)\n            val_loss, val_r2 = validate_epoch(model, val_loader)\n            \n            # Get current learning rate\n            current_lr = scheduler.get_last_lr()[0] if scheduler else LEARNING_RATE\n            \n            print_result(train_loss, val_loss, epoch_start, epoch, num_epochs, val_r2)\n            print(f'  LR: {current_lr:.6f}')\n\n        r2.append(val_r2.item())\n        fold_models.append(model)\n        print(f'Fold {fold + 1} complete!')\n\n    overall_r2 = np.array(r2).mean()\n    \n    print(f'\\nOverall R² across all folds: {overall_r2:.4f}')\n\n    return fold_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:11:00.019911Z","iopub.execute_input":"2025-11-20T17:11:00.020165Z","iopub.status.idle":"2025-11-20T17:11:00.040248Z","shell.execute_reply.started":"2025-11-20T17:11:00.020143Z","shell.execute_reply":"2025-11-20T17:11:00.039632Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"pretrained_backbone = pretrain_phase(extra_df, extra_img_path, num_epochs=1)","metadata":{"execution":{"iopub.status.busy":"2025-11-20T17:11:00.041154Z","iopub.execute_input":"2025-11-20T17:11:00.041395Z","iopub.status.idle":"2025-11-20T17:11:28.308809Z","shell.execute_reply.started":"2025-11-20T17:11:00.041371Z","shell.execute_reply":"2025-11-20T17:11:28.308137Z"},"trusted":true,"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"==================================================\nPHASE 1: PRE-TRAINING ON EXTRA DATASET\nPre-train Epoch 1/1 - Loss: 65.7171\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"### NUM_FOLDS\n# NUM_FT_EPOCHS\nkfold = GroupKFold(n_splits=NUM_FOLDS)\ngroups = dataset_df['Month']\nsplits = kfold.split(dataset_df, groups=groups)\nfold_models = []\nloader_generator = torch.Generator().manual_seed(SET_SEED)\n\nfinal_model = finetune_phase(pretrained_backbone, num_epochs=40, quick=False)\n# Epoch 1/40 - Train Loss: 0.1655, Val Loss: 0.1425 | R²: 0.1264 | Time: 1m 2s","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T17:11:28.310174Z","iopub.execute_input":"2025-11-20T17:11:28.310375Z","execution_failed":"2025-11-20T19:26:40.474Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nPHASE 2: FINE-TUNING ON COMPETITION DATA\nUsing OneCycleLR scheduler with max_lr=0.001\nMixed precision: True\n\n--- Fold 1/3 ---\nEpoch 1/40 - Train Loss: 0.1653, Val Loss: 0.1525 | R²: 0.0690 | Time: 0m 45s\n  LR: 0.000233\nEpoch 2/40 - Train Loss: 0.1617, Val Loss: 0.1341 | R²: 0.1751 | Time: 0m 45s\n  LR: 0.000553\nEpoch 3/40 - Train Loss: 0.1583, Val Loss: 0.1728 | R²: -0.0935 | Time: 0m 45s\n  LR: 0.000871\nEpoch 4/40 - Train Loss: 0.1588, Val Loss: 0.1532 | R²: 0.0540 | Time: 0m 45s\n  LR: 0.001000\nEpoch 5/40 - Train Loss: 0.1583, Val Loss: 0.1551 | R²: 0.0333 | Time: 0m 45s\n  LR: 0.000998\nEpoch 6/40 - Train Loss: 0.1566, Val Loss: 0.1974 | R²: -0.2777 | Time: 0m 44s\n  LR: 0.000992\nEpoch 7/40 - Train Loss: 0.1565, Val Loss: 0.1522 | R²: 0.0523 | Time: 0m 45s\n  LR: 0.000983\nEpoch 8/40 - Train Loss: 0.1523, Val Loss: 0.1522 | R²: 0.0516 | Time: 0m 45s\n  LR: 0.000970\nEpoch 9/40 - Train Loss: 0.1542, Val Loss: 0.1569 | R²: 0.0225 | Time: 0m 44s\n  LR: 0.000953\nEpoch 10/40 - Train Loss: 0.1486, Val Loss: 0.1564 | R²: 0.0280 | Time: 0m 44s\n  LR: 0.000933\nEpoch 11/40 - Train Loss: 0.1469, Val Loss: 0.1536 | R²: 0.0445 | Time: 0m 44s\n  LR: 0.000909\nEpoch 12/40 - Train Loss: 0.1474, Val Loss: 0.1512 | R²: 0.0638 | Time: 0m 44s\n  LR: 0.000883\nEpoch 13/40 - Train Loss: 0.1475, Val Loss: 0.1488 | R²: 0.0801 | Time: 0m 44s\n  LR: 0.000853\nEpoch 14/40 - Train Loss: 0.1458, Val Loss: 0.1612 | R²: -0.0105 | Time: 0m 44s\n  LR: 0.000821\nEpoch 15/40 - Train Loss: 0.1447, Val Loss: 0.1531 | R²: 0.0486 | Time: 0m 44s\n  LR: 0.000786\nEpoch 16/40 - Train Loss: 0.1438, Val Loss: 0.1498 | R²: 0.0738 | Time: 0m 45s\n  LR: 0.000750\nEpoch 17/40 - Train Loss: 0.1419, Val Loss: 0.1517 | R²: 0.0572 | Time: 0m 44s\n  LR: 0.000711\nEpoch 18/40 - Train Loss: 0.1444, Val Loss: 0.1456 | R²: 0.1021 | Time: 0m 45s\n  LR: 0.000671\nEpoch 19/40 - Train Loss: 0.1400, Val Loss: 0.1553 | R²: 0.0378 | Time: 0m 44s\n  LR: 0.000629\nEpoch 20/40 - Train Loss: 0.1386, Val Loss: 0.1517 | R²: 0.0634 | Time: 0m 44s\n  LR: 0.000587\nEpoch 21/40 - Train Loss: 0.1353, Val Loss: 0.1497 | R²: 0.0741 | Time: 0m 44s\n  LR: 0.000543\nEpoch 22/40 - Train Loss: 0.1359, Val Loss: 0.1433 | R²: 0.1201 | Time: 0m 44s\n  LR: 0.000500\nEpoch 23/40 - Train Loss: 0.1316, Val Loss: 0.1469 | R²: 0.0942 | Time: 0m 44s\n  LR: 0.000456\nEpoch 24/40 - Train Loss: 0.1294, Val Loss: 0.1468 | R²: 0.0938 | Time: 0m 44s\n  LR: 0.000413\nEpoch 25/40 - Train Loss: 0.1299, Val Loss: 0.1378 | R²: 0.1599 | Time: 0m 44s\n  LR: 0.000371\nEpoch 26/40 - Train Loss: 0.1239, Val Loss: 0.1421 | R²: 0.1278 | Time: 0m 44s\n  LR: 0.000329\nEpoch 27/40 - Train Loss: 0.1220, Val Loss: 0.1386 | R²: 0.1520 | Time: 0m 44s\n  LR: 0.000289\nEpoch 28/40 - Train Loss: 0.1214, Val Loss: 0.1443 | R²: 0.1160 | Time: 0m 44s\n  LR: 0.000250\nEpoch 29/40 - Train Loss: 0.1168, Val Loss: 0.1454 | R²: 0.1073 | Time: 0m 44s\n  LR: 0.000213\nEpoch 30/40 - Train Loss: 0.1140, Val Loss: 0.1422 | R²: 0.1290 | Time: 0m 45s\n  LR: 0.000179\nEpoch 31/40 - Train Loss: 0.1111, Val Loss: 0.1412 | R²: 0.1363 | Time: 0m 45s\n  LR: 0.000147\nEpoch 32/40 - Train Loss: 0.1133, Val Loss: 0.1440 | R²: 0.1146 | Time: 0m 45s\n  LR: 0.000117\nEpoch 33/40 - Train Loss: 0.1120, Val Loss: 0.1428 | R²: 0.1237 | Time: 0m 45s\n  LR: 0.000091\nEpoch 34/40 - Train Loss: 0.1097, Val Loss: 0.1430 | R²: 0.1222 | Time: 0m 44s\n  LR: 0.000068\nEpoch 35/40 - Train Loss: 0.1071, Val Loss: 0.1433 | R²: 0.1206 | Time: 0m 45s\n  LR: 0.000047\nEpoch 36/40 - Train Loss: 0.1065, Val Loss: 0.1435 | R²: 0.1192 | Time: 0m 45s\n  LR: 0.000031\nEpoch 37/40 - Train Loss: 0.1066, Val Loss: 0.1443 | R²: 0.1133 | Time: 0m 45s\n  LR: 0.000018\nEpoch 38/40 - Train Loss: 0.1064, Val Loss: 0.1447 | R²: 0.1111 | Time: 0m 45s\n  LR: 0.000008\nEpoch 39/40 - Train Loss: 0.1054, Val Loss: 0.1445 | R²: 0.1125 | Time: 0m 45s\n  LR: 0.000003\nEpoch 40/40 - Train Loss: 0.1086, Val Loss: 0.1444 | R²: 0.1131 | Time: 0m 45s\n  LR: 0.000001\nFold 1 complete!\n\n--- Fold 2/3 ---\nEpoch 1/40 - Train Loss: 0.1675, Val Loss: 0.1494 | R²: 0.0413 | Time: 0m 45s\n  LR: 0.000233\nEpoch 2/40 - Train Loss: 0.1571, Val Loss: 0.1624 | R²: -0.0265 | Time: 0m 44s\n  LR: 0.000553\nEpoch 3/40 - Train Loss: 0.1684, Val Loss: 0.1636 | R²: -0.0414 | Time: 0m 45s\n  LR: 0.000871\nEpoch 4/40 - Train Loss: 0.1603, Val Loss: 0.1498 | R²: 0.0479 | Time: 0m 45s\n  LR: 0.001000\nEpoch 5/40 - Train Loss: 0.1554, Val Loss: 0.1492 | R²: 0.0521 | Time: 0m 45s\n  LR: 0.000998\nEpoch 6/40 - Train Loss: 0.1554, Val Loss: 0.1520 | R²: 0.0354 | Time: 0m 45s\n  LR: 0.000992\nEpoch 7/40 - Train Loss: 0.1554, Val Loss: 0.1491 | R²: 0.0525 | Time: 0m 45s\n  LR: 0.000983\nEpoch 8/40 - Train Loss: 0.1532, Val Loss: 0.1528 | R²: 0.0296 | Time: 0m 45s\n  LR: 0.000970\nEpoch 9/40 - Train Loss: 0.1576, Val Loss: 0.1512 | R²: 0.0384 | Time: 0m 45s\n  LR: 0.000953\nEpoch 10/40 - Train Loss: 0.1522, Val Loss: 0.1464 | R²: 0.0655 | Time: 0m 45s\n  LR: 0.000933\nEpoch 11/40 - Train Loss: 0.1513, Val Loss: 0.1455 | R²: 0.0724 | Time: 0m 45s\n  LR: 0.000909\nEpoch 12/40 - Train Loss: 0.1513, Val Loss: 0.1490 | R²: 0.0522 | Time: 0m 45s\n  LR: 0.000883\nEpoch 13/40 - Train Loss: 0.1487, Val Loss: 0.1462 | R²: 0.0682 | Time: 0m 45s\n  LR: 0.000853\nEpoch 14/40 - Train Loss: 0.1463, Val Loss: 0.1477 | R²: 0.0603 | Time: 0m 45s\n  LR: 0.000821\nEpoch 15/40 - Train Loss: 0.1489, Val Loss: 0.1458 | R²: 0.0709 | Time: 0m 44s\n  LR: 0.000786\nEpoch 16/40 - Train Loss: 0.1454, Val Loss: 0.1446 | R²: 0.0785 | Time: 0m 44s\n  LR: 0.000750\nEpoch 17/40 - Train Loss: 0.1458, Val Loss: 0.1462 | R²: 0.0671 | Time: 0m 45s\n  LR: 0.000711\nEpoch 18/40 - Train Loss: 0.1469, Val Loss: 0.1479 | R²: 0.0602 | Time: 0m 45s\n  LR: 0.000671\nEpoch 19/40 - Train Loss: 0.1437, Val Loss: 0.1484 | R²: 0.0575 | Time: 0m 45s\n  LR: 0.000629\nEpoch 20/40 - Train Loss: 0.1433, Val Loss: 0.1490 | R²: 0.0511 | Time: 0m 44s\n  LR: 0.000587\nEpoch 21/40 - Train Loss: 0.1403, Val Loss: 0.1494 | R²: 0.0489 | Time: 0m 44s\n  LR: 0.000543\nEpoch 22/40 - Train Loss: 0.1386, Val Loss: 0.1616 | R²: -0.0301 | Time: 0m 45s\n  LR: 0.000500\nEpoch 23/40 - Train Loss: 0.1445, Val Loss: 0.1448 | R²: 0.0732 | Time: 0m 44s\n  LR: 0.000456\nEpoch 24/40 - Train Loss: 0.1391, Val Loss: 0.1420 | R²: 0.0948 | Time: 0m 45s\n  LR: 0.000413\nEpoch 25/40 - Train Loss: 0.1356, Val Loss: 0.1521 | R²: 0.0246 | Time: 0m 44s\n  LR: 0.000371\nEpoch 26/40 - Train Loss: 0.1350, Val Loss: 0.1422 | R²: 0.0938 | Time: 0m 44s\n  LR: 0.000329\nEpoch 27/40 - Train Loss: 0.1306, Val Loss: 0.1415 | R²: 0.0947 | Time: 0m 44s\n  LR: 0.000289\nEpoch 28/40 - Train Loss: 0.1257, Val Loss: 0.1353 | R²: 0.1352 | Time: 0m 44s\n  LR: 0.000250\nEpoch 29/40 - Train Loss: 0.1262, Val Loss: 0.1369 | R²: 0.1224 | Time: 0m 44s\n  LR: 0.000213\nEpoch 30/40 - Train Loss: 0.1222, Val Loss: 0.1374 | R²: 0.1218 | Time: 0m 44s\n  LR: 0.000179\nEpoch 31/40 - Train Loss: 0.1199, Val Loss: 0.1357 | R²: 0.1325 | Time: 0m 44s\n  LR: 0.000147\nEpoch 32/40 - Train Loss: 0.1167, Val Loss: 0.1392 | R²: 0.1031 | Time: 0m 44s\n  LR: 0.000117\nEpoch 33/40 - Train Loss: 0.1148, Val Loss: 0.1384 | R²: 0.1110 | Time: 0m 44s\n  LR: 0.000091\nEpoch 34/40 - Train Loss: 0.1143, Val Loss: 0.1354 | R²: 0.1302 | Time: 0m 44s\n  LR: 0.000068\nEpoch 35/40 - Train Loss: 0.1131, Val Loss: 0.1387 | R²: 0.1058 | Time: 0m 44s\n  LR: 0.000047\nEpoch 36/40 - Train Loss: 0.1119, Val Loss: 0.1388 | R²: 0.1051 | Time: 0m 44s\n  LR: 0.000031\nEpoch 37/40 - Train Loss: 0.1111, Val Loss: 0.1384 | R²: 0.1077 | Time: 0m 44s\n  LR: 0.000018\nEpoch 38/40 - Train Loss: 0.1104, Val Loss: 0.1389 | R²: 0.1042 | Time: 0m 44s\n  LR: 0.000008\nEpoch 39/40 - Train Loss: 0.1117, Val Loss: 0.1388 | R²: 0.1047 | Time: 0m 45s\n  LR: 0.000003\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"test_dataset = BiomassDataset(test_df, base_path, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n\nensemble_outputs = []\nwith torch.no_grad():\n    for image, img_path in test_loader:\n        image = image.to(device)\n        \n        # Get predictions from all models\n        all_outputs = []\n        for model in fold_models:\n            model.eval()\n            outputs = model(image)\n            print(outputs)\n            all_outputs.append(outputs)\n            ensemble_outputs.append(torch.stack(all_outputs).mean(dim=0))\n        \nensemble_outputs = torch.cat(ensemble_outputs, dim=0)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T19:26:40.503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = BiomassDataset(test_df, base_path, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n\n# Dictionary to store predictions grouped by image_path\npreds_by_image = defaultdict(list)\n\nwith torch.no_grad():\n    for image, img_paths in test_loader:\n        image = image.to(device)\n        \n        # Get ensemble predictions from all models\n        all_outputs = []\n        for model in fold_models:\n            model.eval()\n            outputs = model(image)\n            all_outputs.append(outputs)\n        \n        # Average across models (ensemble)\n        ensemble_batch = torch.stack(all_outputs).mean(dim=0)  # [batch_size, 5]\n        \n        # Group predictions by image_path\n        # Since BiomassDataset returns 2 items per image (left/right halves),\n        # img_paths is a tuple/list of image paths (may have duplicates)\n        # We group by image_path and will average left/right later\n        batch_size = ensemble_batch.shape[0]\n        for i in range(batch_size):\n            img_path = img_paths[i]  # Get the image_path for this batch item\n            preds_by_image[img_path].append(ensemble_batch[i].cpu())\n\n# Average left/right predictions for each image\nimage_predictions = {}\nfor img_path, preds in preds_by_image.items():\n    # Stack and average: [num_halves, 5] -> [5]\n    # Each image should have exactly 2 predictions (left + right)\n    stacked_preds = torch.stack(preds)  # [2, 5] for left and right halves\n    image_predictions[img_path] = stacked_preds.mean(dim=0)  # Average to [5]ee\n\n# Check predictions for first image\nif len(image_predictions) > 0:\n    first_img_path = list(image_predictions.keys())[0]\n    print(f\"Image: {first_img_path}\")\n    print(f\"Predictions: {image_predictions[first_img_path].tolist()}\")\n    print(f\"Target columns: {TARGET_COLS}\")\nelse:\n    print(\"No predictions available yet. Run the test prediction cell first.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T19:26:40.507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Denormalize all predictions back to original scale\nfor img_path in image_predictions:\n    image_predictions[img_path] = denormalize_targets(image_predictions[img_path])\n\nprint(f\"Denormalized predictions for {len(image_predictions)} images\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T19:26:40.508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_outputs[0].tolist()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T19:26:40.510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.read_csv(submission_path)\n\nfor i, row in submission_df.iterrows():\n    img_path = test_df[test_df['sample_id'] == row['sample_id']]['image_path'].values[0]\n    target_name = test_df[test_df['sample_id'] == row['sample_id']]['target_name'].values[0]\n    \n    preds = ensemble_outputs\n    target_idx = TARGET_COLS.index(target_name)\n    submission_df.at[i, 'target'] = ensemble_outputs[i, target_idx].item()\n\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-20T19:26:40.510Z"}},"outputs":[],"execution_count":null}]}